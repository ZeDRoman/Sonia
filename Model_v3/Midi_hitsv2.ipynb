{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from mido import Message, MetaMessage\n",
    "import mido\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "pwd = \"/home/zedroman/Documents/Sonia_Data/Songs/anime_samples2/\"\n",
    "savepwd=\"/home/zedroman/Documents/Sonia_Data/Songs/_test2/\"\n",
    "music = sorted([f for f in os.listdir(pwd) if f[len(f)-4:len(f)] == \".mid\"])\n",
    "\n",
    "\n",
    "tempo = 500000 * 5\n",
    "hidden_size = 512\n",
    "max_len = 100\n",
    "\n",
    "velocity_range = [0, 64]\n",
    "time_range = [0, 150, 300];\n",
    "tempo = 2000000 // 3\n",
    "pedal_max = 20\n",
    "max_len = 500\n",
    "use_pedal = False\n",
    "\n",
    "decoder_params = [velocity_range, time_range, tempo, pedal_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.mid', '1.mid', '10.mid', '11.mid', '2.mid', '4.mid', '5.mid', '6.mid', '7.mid', '8.mid']\n"
     ]
    }
   ],
   "source": [
    "music = music[0:10]\n",
    "print(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device=\"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random(music):\n",
    "    randoms = []\n",
    "    for i in range(len(music)):\n",
    "        r = []\n",
    "        for j in range(3):\n",
    "            r.append([random.random() * 10 for i in range(hidden_size)])\n",
    "        randoms.append(r)\n",
    "    return randoms\n",
    "random_starts = create_random(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{61: 0, 66: 1, 68: 2, 69: 3, 38: 4, 50: 5, 65: 6, 59: 7, 37: 8, 49: 9, 57: 10, 42: 11, 30: 12, 62: 13, 35: 14, 47: 15, 71: 16, 40: 17, 52: 18, 64: 19, 33: 20, 45: 21, 73: 22, 56: 23, 54: 24, 32: 25, 44: 26, 76: 27, 74: 28, 75: 29, 39: 30, 77: 31, 78: 32, 51: 33, 79: 34, 72: 35, 70: 36, 67: 37, 36: 38, 48: 39, 34: 40, 46: 41, 82: 42, 63: 43, 84: 44, 60: 45, 41: 46, 53: 47, 80: 48, 58: 49, 55: 50, 43: 51, 27: 52, 29: 53, 31: 54, 81: 55, 83: 56, 86: 57, 28: 58, 26: 59, 88: 60, 85: 61, 95: 62, 90: 63, 91: 64, 96: 65, 93: 66, 87: 67}\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "use_notes = {}\n",
    "class_note = {}\n",
    "for file in (music):\n",
    "    midi_file = mido.MidiFile(pwd + file)\n",
    "    for track in midi_file.tracks:\n",
    "        for msg in track:\n",
    "            if (msg.type == \"note_on\"):\n",
    "                if (msg.note not in use_notes):\n",
    "                    class_note[len(use_notes)] = msg.note\n",
    "                    use_notes[msg.note] = len(use_notes)\n",
    "classes = len(use_notes) * len(time_range) * len(velocity_range)\n",
    "sos = classes\n",
    "classes += 1\n",
    "print(use_notes)\n",
    "print(classes)\n",
    "decoder_params.append(class_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'msg_to_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb2a5cb608f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"note_on\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtime_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_note\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_to_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_to_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_to_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'msg_to_class' is not defined"
     ]
    }
   ],
   "source": [
    "msg = Message(\"note_on\", note = class_note[0], velocity = 0, time= time_range[1])\n",
    "print(class_note[0])\n",
    "print(msg_to_class(msg))\n",
    "print(class_to_msg(msg_to_class(msg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_find(l, n):\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == n:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def msg_to_class(msg):\n",
    "    note = use_notes[msg.note]\n",
    "    t = list_find(time_range, msg.time)\n",
    "    v = list_find(velocity_range, msg.velocity)\n",
    "    return v * len(use_notes) * len(time_range) + t * len(use_notes) + note\n",
    "    \n",
    "def class_to_msg(n):\n",
    "    note = class_note[n % len(use_notes)]\n",
    "    n //= len(use_notes)\n",
    "    t = time_range[n % len(time_range)]\n",
    "    n //= len(time_range)\n",
    "    v = velocity_range[n]\n",
    "    return Message(\"note_on\", note = note, velocity = v, time= t)\n",
    "\n",
    "\n",
    "def midi_to_list(mid=None, pwd=None, tensor=True):\n",
    "    if(mid==None):\n",
    "          mid = mido.MidiFile(pwd)\n",
    "    sample = []\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        for msg in track:\n",
    "            if (msg.type == \"note_on\"):\n",
    "                sample.append(msg_to_class(msg))\n",
    "    if (tensor):\n",
    "        return torch.tensor(sample, device=device)\n",
    "    else:\n",
    "        return sample\n",
    "\n",
    "def list_to_midi(sample):\n",
    "    midi = mido.MidiFile(type=0)\n",
    "    tr = mido.MidiTrack()\n",
    "    midi.tracks.append(tr)\n",
    "    tr.append(MetaMessage(\"set_tempo\", tempo=tempo, time=0))\n",
    "    \n",
    "    tr.append(MetaMessage(\"key_signature\", key='A', time=0))\n",
    "    \n",
    "    pedal = pedal_max\n",
    "    last_notes = []\n",
    "    \n",
    "    for i in sample:\n",
    "        if (use_pedal):\n",
    "            if (pedal == 0):\n",
    "                for j in range(len(last_notes) - 1):\n",
    "                    tr.append(Message(\"note_off\", note=last_notes[j], velocity=0, time=0, channel=0))\n",
    "                pedal = pedal_max\n",
    "                last_notes = [last_notes[-1]]\n",
    "        tr.append(class_to_msg(i))\n",
    "        if (use_pedal):\n",
    "            pedal -= 1\n",
    "            last_notes.append(class_note[i % len(use_notes)])\n",
    "    if (use_pedal):\n",
    "        for i in last_notes:\n",
    "            tr.append(Message(\"note_off\", note=i, velocity=0, time=0, channel=0))\n",
    "    tr.append(MetaMessage(\"end_of_track\", time = 0))\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.mid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file in (music):\n",
    "    midi_file = mido.MidiFile(pwd + file)\n",
    "    sample = midi_to_list(mid=midi_file, tensor=False)\n",
    "    print(file)\n",
    "    midi = list_to_midi(sample)\n",
    "    midi.save(\"/home/zedroman/Documents/Sonia_Data/Songs/_test2/test_to.mid\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, other):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru1 = nn.GRU(classes, hidden_size)\n",
    "        self.gru2 = nn.GRU(hidden_size, hidden_size)\n",
    "        self.gru3 = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.velocity = other[0]\n",
    "        self.time_range = other[1]\n",
    "        self.tempo = other[2]\n",
    "        self.pedal_max = other[3]\n",
    "        self.notes = other[4]\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden[0] = self.gru1(input, hidden[0])\n",
    "        output = F.relu(output)\n",
    "        output, hidden[1] = self.gru2(output, hidden[1])\n",
    "        output = F.relu(output)\n",
    "        output, hidden[2] = self.gru3(output, hidden[2])\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot(c):\n",
    "    x = torch.zeros(classes, device=device, dtype=torch.float)\n",
    "    x[c] = 1;\n",
    "    return x.view(1,1,-1)\n",
    "\n",
    "def train(target_tensor, decoder, decoder_optimizer, criterion, max_length=max_len, num = -1):\n",
    "    decoder_optimizer.zero_grad()\n",
    "    target_length = target_tensor.size(0)\n",
    "    loss = 0\n",
    "    \n",
    "    decoder_input = one_hot(sos)\n",
    "    decoder_hidden = [torch.tensor(random_starts[num][0], device=device, dtype=torch.float).view(1,1,-1),\n",
    "                        torch.tensor(random_starts[num][1], device=device, dtype=torch.float).view(1,1,-1),\n",
    "                        torch.tensor(random_starts[num][2], device=device, dtype=torch.float).view(1,1,-1)]\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        loss += criterion(decoder_output, target_tensor[di:di+1])\n",
    "        decoder_input = one_hot(target_tensor[di])  # Teacher forcing\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(decoder, n_iters,decoder_optimizer, print_every=len(music), epoch=0, save_mod=False):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    criterion = nn.NLLLoss()\n",
    "    save = 20\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = music[iter % (len(music))]\n",
    "        midi_file = mido.MidiFile(pwd + training_pair)\n",
    "        target_tensor = midi_to_list(mid=midi_file)\n",
    "        loss = train(target_tensor,\n",
    "                     decoder, decoder_optimizer, criterion, num = iter % (len(music)))\n",
    "        print_loss_total += loss\n",
    "\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            save -= 1\n",
    "            last_loss = print_loss_total / print_every\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            if (save == 0 and save_mod):\n",
    "                save = 20\n",
    "                torch.save({\n",
    "                    'model_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                    'random_starts' : random_starts,\n",
    "                    'velocity_range' : velocity_range,\n",
    "                    'time_range' : time_range,\n",
    "                    'tempo' : tempo,\n",
    "                    'pedal_max' : pedal_max,\n",
    "                    'class_note' : class_note,\n",
    "                    }, '/home/zedroman/Documents/Sonia/models/bethoven2')\n",
    "                with open('/home/zedroman/Documents/Sonia/models/bethoven2_classes', 'w') as f: \n",
    "                    f.write(str(classes))\n",
    "                    f.write(' ')\n",
    "                    f.write(str(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "decoder = DecoderRNN(hidden_size, classes, decoder_params).to(device)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters() , lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 198m 47s) (10 0%) 0.0143\n",
      "1m 58s (- 195m 39s) (20 1%) 0.0141\n",
      "2m 57s (- 194m 16s) (30 1%) 0.0138\n",
      "3m 55s (- 192m 25s) (40 2%) 0.0142\n",
      "4m 53s (- 190m 38s) (50 2%) 0.0141\n",
      "5m 52s (- 189m 56s) (60 3%) 0.0139\n",
      "6m 49s (- 188m 15s) (70 3%) 0.0139\n",
      "7m 49s (- 187m 39s) (80 4%) 0.0137\n",
      "8m 48s (- 186m 47s) (90 4%) 0.0131\n",
      "9m 47s (- 186m 6s) (100 5%) 0.0128\n",
      "10m 46s (- 185m 4s) (110 5%) 0.0129\n",
      "11m 45s (- 184m 20s) (120 6%) 0.0129\n",
      "12m 47s (- 183m 59s) (130 6%) 0.0125\n",
      "13m 45s (- 182m 46s) (140 7%) 0.0124\n",
      "14m 43s (- 181m 42s) (150 7%) 0.0121\n",
      "15m 41s (- 180m 23s) (160 8%) 0.0115\n",
      "16m 38s (- 179m 6s) (170 8%) 0.0112\n",
      "17m 35s (- 177m 51s) (180 9%) 0.0109\n",
      "18m 33s (- 176m 46s) (190 9%) 0.0107\n",
      "19m 32s (- 175m 51s) (200 10%) 0.0105\n",
      "20m 32s (- 175m 7s) (210 10%) 0.0104\n",
      "21m 30s (- 174m 1s) (220 11%) 0.0103\n",
      "22m 27s (- 172m 51s) (230 11%) 0.0103\n",
      "23m 24s (- 171m 42s) (240 12%) 0.0101\n",
      "24m 22s (- 170m 34s) (250 12%) 0.0100\n",
      "25m 18s (- 169m 25s) (260 13%) 0.0097\n",
      "26m 17s (- 168m 24s) (270 13%) 0.0097\n",
      "27m 16s (- 167m 30s) (280 14%) 0.0095\n",
      "28m 15s (- 166m 40s) (290 14%) 0.0094\n",
      "29m 16s (- 165m 51s) (300 15%) 0.0093\n",
      "30m 15s (- 164m 56s) (310 15%) 0.0092\n",
      "31m 15s (- 164m 8s) (320 16%) 0.0090\n",
      "32m 16s (- 163m 19s) (330 16%) 0.0088\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-58eec83b83af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_mod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2daaf5f471fc>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(decoder, n_iters, decoder_optimizer, print_every, epoch, save_mod)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         loss = train(target_tensor,\n\u001b[0;32m---> 11\u001b[0;31m                      decoder, decoder_optimizer, criterion, num = iter % (len(music)))\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-64b58f051a8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target_tensor, decoder, decoder_optimizer, criterion, max_length, num)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainIters(decoder, 2000, decoder_optimizer,save_mod=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zedroman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/zedroman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.12499999999992\n",
      "22.124999999999982\n",
      "40.37500000000002\n",
      "42.75000000000005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8c83d50a387a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0muse_pedal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8c83d50a387a>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(number, decoder)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_music\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8c83d50a387a>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(decoder, num, max_length)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 decoder_input, decoder_hidden)\n\u001b[1;32m     17\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtopv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtopv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mchosen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtopv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msumm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate(decoder,num=-1, max_length=max_len):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        decoder_input = one_hot(sos)\n",
    "        decoder_hidden = []\n",
    "        for j in range(3):\n",
    "            decoder_hidden.append([random.random() * 10 for i in range(hidden_size)])\n",
    "        decoder_hidden =   [torch.tensor(decoder_hidden[0], device=device).view(1,1,-1),\n",
    "                        torch.tensor(decoder_hidden[1], device=device).view(1,1,-1),\n",
    "                        torch.tensor(decoder_hidden[2], device=device).view(1,1,-1)]\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(random.randint(1,2))\n",
    "            topv = topv.max().item() - topv.cpu()[0].numpy()\n",
    "            summ = topv.sum()\n",
    "            chosen = np.random.choice(topi[0].cpu(), p= topv / summ)\n",
    "            decoder_input = one_hot(chosen)\n",
    "            decoded_words.append(chosen)\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "def generate(number, decoder):\n",
    "    for i in range(number):\n",
    "        new_music = evaluate(decoder, max_length=1000)\n",
    "        midi = list_to_midi(new_music)\n",
    "        print(midi.length)\n",
    "        midi.save(savepwd +\"test\" + str(i) + \".mid\")\n",
    "    return midi\n",
    "use_pedal=False\n",
    "last = generate(10, decoder)\n",
    "for track in last.tracks:\n",
    "    for msg in track:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'random_starts' : random_starts,\n",
    "            'velocity_range' : velocity_range,\n",
    "            'time_range' : time_range,\n",
    "            'tempo' : tempo,\n",
    "            'pedal_max' : pedal_max,\n",
    "            'class_note' : class_note,\n",
    "            }, '/home/zedroman/Documents/Sonia/models/anime2')\n",
    "with open('/home/zedroman/Documents/Sonia/models/anime2_classes', 'w') as f: \n",
    "    f.write(str(classes))\n",
    "    f.write(' ')\n",
    "    f.write(str(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2 = DecoderRNN(hidden_size, classes, decoder_params).to(device)\n",
    "decoder_optimizer2 = optim.Adam(decoder.parameters() , lr=learning_rate)\n",
    "checkpoint = torch.load('/home/zedroman/Documents/Sonia/models/bethoven')\n",
    "decoder2.load_state_dict(checkpoint['model_state_dict'])\n",
    "random_starts2 = checkpoint['random_starts']\n",
    "decoder_optimizer2.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_starts2==random_starts)\n",
    "print(decoder2==decoder)\n",
    "print(decoder_optimizer2==decoder_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(10, decoder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/zedroman/Documents/Sonia/models/anime_classes') as f: \n",
    "    data = int(f.readlines()[0])\n",
    "    print(data)\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/zedroman/Documents/Sonia/models/anime_classes', 'w') as f: \n",
    "#     f.write(str(classes))\n",
    "#     f.write(' ')\n",
    "#     f.write(str(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "1\n",
      "5\n",
      "9\n",
      "8\n",
      "7\n",
      "5\n",
      "8\n",
      "6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
