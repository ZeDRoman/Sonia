{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        if self.name ==\"phone\":\n",
    "            for word in sentence.split('_'):\n",
    "                self.addWord(word)\n",
    "        else:\n",
    "            for word in list(sentence):\n",
    "                self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('/home/zedroman/Documents/Sonia_Data/eng_phonetics/train.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[s for s in l.split(' ')[0:2]] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 76\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 83194 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "words 30\n",
      "phone 41\n",
      "['CHANTED', 'CH_AE_N_T_IH_D']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "#     print(pairs)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "#     pairs = filterPairs(pairs)\n",
    "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('words', 'phone', True)\n",
    "print(random.choice(pairs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Lang object at 0x7f8a94a8d320>\n",
      "{'L': 2, 'E': 3, 'M': 4, 'I': 5, 'U': 6, 'X': 7, 'N': 8, 'D': 9, 'G': 10, 'S': 11, 'T': 12, 'R': 13, 'P': 14, 'K': 15, 'C': 16, 'O': 17, 'F': 18, 'A': 19, 'B': 20, 'H': 21, 'V': 22, 'Y': 23, 'W': 24, 'J': 25, \"'\": 26, 'Q': 27, 'Z': 28, '-': 29}\n",
      "{'L': 2, 'AH': 3, 'M': 4, 'Y': 5, 'UW': 6, 'AY': 7, 'N': 8, 'D': 9, 'IH': 10, 'NG': 11, 'S': 12, 'T': 13, 'R': 14, 'P': 15, 'K': 16, 'EH': 17, 'AA': 18, 'F': 19, 'ER': 20, 'EY': 21, 'AE': 22, 'Z': 23, 'G': 24, 'B': 25, 'SH': 26, 'V': 27, 'OW': 28, 'AO': 29, 'IY': 30, 'W': 31, 'HH': 32, 'JH': 33, 'CH': 34, 'TH': 35, 'AW': 36, 'OY': 37, 'UH': 38, 'ZH': 39, 'DH': 40}\n"
     ]
    }
   ],
   "source": [
    "print(input_lang)\n",
    "print(input_lang.word2index)\n",
    "print(output_lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size * 2\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence, out, back = False):\n",
    "    if not out:\n",
    "        if back:\n",
    "            return list(reversed([lang.word2index[word] for word in list(sentence)]))\n",
    "        return [lang.word2index[word] for word in list(sentence)]\n",
    "    else:\n",
    "        return [lang.word2index[word] for word in sentence.split('_')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence, out, back = False):\n",
    "    indexes = indexesFromSentence(lang, sentence, out, back)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0], 0)\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1], 1)\n",
    "    back_tensor = tensorFromSentence(input_lang, pair[0], 0, back=True)\n",
    "    return (input_tensor, target_tensor, back_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train(input_tensor, input_tensor_back, target_tensor, encoder, encoder_back, decoder, encoder_optimizer,encoder_back_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_back_hidden = encoder_back.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    encoder_back_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    encoder_back_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        encoder_back_output, encoder_back_hidden = encoder_back(\n",
    "            input_tensor_back[ei], encoder_back_hidden)\n",
    "        encoder_back_outputs[ei] = encoder_back_output[0, 0]\n",
    "\n",
    "    encoder_hidden = torch.cat((encoder_hidden, encoder_back_hidden), 2)\n",
    "    encoder_outputs = torch.cat((encoder_outputs, encoder_back_outputs), 1)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    encoder_back_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [tensorsFromPair(pairs[i])\n",
    "                  for i in range(len(pairs))]\n",
    "\n",
    "def trainIters(encoder, encoder_back, decoder, n_iters, encoder_optimizer, encoder_back_optimizer, decoder_optimizer, print_every=1000, plot_every=100, learning_rate=0.001, epoch=0):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = random.choice(training_pairs)\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        input_tensor_back = training_pair[2]\n",
    "\n",
    "        loss = train(input_tensor, input_tensor_back, target_tensor, encoder, encoder_back,\n",
    "                     decoder, encoder_optimizer,encoder_back_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "#             torch.save(encoder1, '/home/zedroman/Documents/Sonia_Data/test_models2/encoder_epoch{}_{}'.format(epoch, iter))\n",
    "#             torch.save(attn_decoder1, '/home/zedroman/Documents/Sonia_Data/test_models2/decoder_epoch{}_{}'.format(epoch, iter))\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "#         if iter % plot_every == 0:\n",
    "#             plot_loss_avg = plot_loss_total / plot_every\n",
    "#             plot_losses.append(plot_loss_avg)\n",
    "#             plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, encoder_back, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence, 0, 0)\n",
    "        input_tensor_back = tensorFromSentence(input_lang, sentence, 0, 1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_back_hidden = encoder_back.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_back_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "            encoder_back_output, encoder_back_hidden = encoder_back(\n",
    "                input_tensor_back[ei], encoder_back_hidden)\n",
    "            encoder_back_outputs[ei] = encoder_back_output[0, 0]\n",
    "\n",
    "        encoder_hidden = torch.cat((encoder_hidden, encoder_back_hidden), 2)\n",
    "        encoder_outputs = torch.cat((encoder_outputs, encoder_back_outputs), 1)\n",
    "\n",
    "            \n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "#                 decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder,encoder_back, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder,encoder_back, decoder, pair[0])\n",
    "        output_sentence = '_'.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAccuracy(encoder,encoder_back, decoder, choose = 5000):\n",
    "    good = 0\n",
    "    for i in range(choose):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, attentions = evaluate(encoder,encoder_back, decoder, pair[0])\n",
    "        output_sentence = '_'.join(output_words)\n",
    "        if (output_sentence == pair[1]):\n",
    "            good+=1\n",
    "    print(good / choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "# encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# encoder_back = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "epo = 6\n",
    "encoder = torch.load('/home/zedroman/Documents/Sonia_Data/test_models4/encoder_epoch{}'.format(epo)).to(device)\n",
    "encoder_back = torch.load('/home/zedroman/Documents/Sonia_Data/test_models4/encoder_back_epoch{}'.format(epo)).to(device)\n",
    "attn_decoder = torch.load( '/home/zedroman/Documents/Sonia_Data/test_models4/decoder_epoch{}'.format(epo)).to(device)\n",
    "# encoder1.eval()\n",
    "# attn_decoder1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate, momentum=0.9)\n",
    "encoder_back_optimizer = optim.SGD(encoder_back.parameters(), lr=learning_rate, momentum=0.9)\n",
    "decoder_optimizer = optim.SGD(attn_decoder.parameters() , lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 5s (- 34m 47s) (200 0%) 0.2211\n",
      "0m 9s (- 33m 40s) (400 0%) 0.2825\n",
      "0m 14s (- 33m 1s) (600 0%) 0.2515\n",
      "0m 19s (- 32m 49s) (800 0%) 0.3042\n",
      "0m 23s (- 32m 46s) (1000 1%) 0.2438\n",
      "0m 28s (- 32m 50s) (1200 1%) 0.2425\n",
      "0m 33s (- 32m 49s) (1400 1%) 0.2973\n",
      "0m 38s (- 32m 49s) (1600 1%) 0.2649\n",
      "0m 43s (- 32m 37s) (1800 2%) 0.2960\n",
      "0m 47s (- 32m 27s) (2000 2%) 0.2047\n",
      "0m 52s (- 32m 22s) (2200 2%) 0.2808\n",
      "0m 57s (- 32m 15s) (2400 2%) 0.3041\n",
      "1m 2s (- 32m 7s) (2600 3%) 0.2453\n",
      "1m 7s (- 32m 4s) (2800 3%) 0.2348\n",
      "1m 11s (- 32m 1s) (3000 3%) 0.2783\n",
      "1m 16s (- 31m 55s) (3200 3%) 0.2644\n",
      "1m 21s (- 31m 48s) (3400 4%) 0.2741\n",
      "1m 26s (- 31m 44s) (3600 4%) 0.2757\n",
      "1m 30s (- 31m 37s) (3800 4%) 0.2535\n",
      "1m 35s (- 31m 30s) (4000 4%) 0.2771\n",
      "1m 40s (- 31m 24s) (4200 5%) 0.2562\n",
      "1m 45s (- 31m 26s) (4400 5%) 0.2898\n",
      "1m 50s (- 31m 21s) (4600 5%) 0.2481\n",
      "1m 54s (- 31m 16s) (4800 5%) 0.2884\n",
      "1m 59s (- 31m 11s) (5000 6%) 0.2120\n",
      "2m 4s (- 31m 10s) (5200 6%) 0.2267\n",
      "2m 9s (- 31m 8s) (5400 6%) 0.3009\n",
      "2m 14s (- 31m 3s) (5600 6%) 0.2861\n",
      "2m 19s (- 30m 57s) (5800 6%) 0.2853\n",
      "2m 24s (- 30m 56s) (6000 7%) 0.2447\n",
      "2m 29s (- 30m 54s) (6200 7%) 0.2687\n",
      "2m 34s (- 30m 48s) (6400 7%) 0.2873\n",
      "2m 38s (- 30m 42s) (6600 7%) 0.2622\n",
      "2m 43s (- 30m 37s) (6800 8%) 0.2572\n",
      "2m 48s (- 30m 31s) (7000 8%) 0.2509\n",
      "2m 53s (- 30m 26s) (7200 8%) 0.2500\n",
      "2m 57s (- 30m 22s) (7400 8%) 0.2983\n",
      "3m 2s (- 30m 17s) (7600 9%) 0.2757\n",
      "3m 7s (- 30m 12s) (7800 9%) 0.2341\n",
      "3m 12s (- 30m 8s) (8000 9%) 0.2337\n",
      "3m 17s (- 30m 3s) (8200 9%) 0.2637\n",
      "3m 22s (- 29m 59s) (8400 10%) 0.2548\n",
      "3m 26s (- 29m 54s) (8600 10%) 0.3042\n",
      "3m 31s (- 29m 50s) (8800 10%) 0.2595\n",
      "3m 36s (- 29m 45s) (9000 10%) 0.2360\n",
      "3m 41s (- 29m 41s) (9200 11%) 0.2413\n",
      "3m 46s (- 29m 35s) (9400 11%) 0.2557\n",
      "3m 50s (- 29m 30s) (9600 11%) 0.2628\n",
      "3m 55s (- 29m 25s) (9800 11%) 0.2317\n",
      "4m 0s (- 29m 20s) (10000 12%) 0.2571\n",
      "4m 5s (- 29m 15s) (10200 12%) 0.2343\n",
      "4m 10s (- 29m 10s) (10400 12%) 0.2565\n",
      "4m 14s (- 29m 5s) (10600 12%) 0.2371\n",
      "4m 19s (- 29m 1s) (10800 12%) 0.2270\n",
      "4m 24s (- 28m 57s) (11000 13%) 0.2724\n",
      "4m 29s (- 28m 52s) (11200 13%) 0.2948\n",
      "4m 34s (- 28m 46s) (11400 13%) 0.2843\n",
      "4m 38s (- 28m 41s) (11600 13%) 0.3027\n",
      "4m 43s (- 28m 35s) (11800 14%) 0.2809\n",
      "4m 48s (- 28m 31s) (12000 14%) 0.2731\n",
      "4m 53s (- 28m 26s) (12200 14%) 0.2820\n",
      "4m 58s (- 28m 22s) (12400 14%) 0.2561\n",
      "5m 3s (- 28m 18s) (12600 15%) 0.3081\n",
      "5m 8s (- 28m 14s) (12800 15%) 0.2727\n",
      "5m 13s (- 28m 10s) (13000 15%) 0.2912\n",
      "5m 17s (- 28m 6s) (13200 15%) 0.2583\n",
      "5m 22s (- 28m 1s) (13400 16%) 0.2527\n",
      "5m 27s (- 27m 55s) (13600 16%) 0.2751\n",
      "5m 32s (- 27m 51s) (13800 16%) 0.2808\n",
      "5m 37s (- 27m 46s) (14000 16%) 0.2430\n",
      "5m 41s (- 27m 41s) (14200 17%) 0.2404\n",
      "5m 46s (- 27m 37s) (14400 17%) 0.2751\n",
      "5m 51s (- 27m 32s) (14600 17%) 0.3172\n",
      "5m 56s (- 27m 28s) (14800 17%) 0.2406\n",
      "6m 1s (- 27m 22s) (15000 18%) 0.2320\n",
      "6m 6s (- 27m 17s) (15200 18%) 0.3319\n",
      "6m 10s (- 27m 12s) (15400 18%) 0.2842\n",
      "6m 15s (- 27m 7s) (15600 18%) 0.2303\n",
      "6m 20s (- 27m 2s) (15800 18%) 0.3022\n",
      "6m 25s (- 26m 57s) (16000 19%) 0.2627\n",
      "6m 29s (- 26m 52s) (16200 19%) 0.2712\n",
      "6m 34s (- 26m 46s) (16400 19%) 0.2462\n",
      "6m 38s (- 26m 40s) (16600 19%) 0.2803\n",
      "6m 43s (- 26m 35s) (16800 20%) 0.2330\n",
      "6m 48s (- 26m 31s) (17000 20%) 0.2803\n",
      "6m 53s (- 26m 26s) (17200 20%) 0.2470\n",
      "6m 58s (- 26m 21s) (17400 20%) 0.2387\n",
      "7m 3s (- 26m 16s) (17600 21%) 0.2305\n",
      "7m 7s (- 26m 12s) (17800 21%) 0.2712\n",
      "7m 12s (- 26m 7s) (18000 21%) 0.2210\n",
      "7m 17s (- 26m 2s) (18200 21%) 0.2487\n",
      "7m 22s (- 25m 58s) (18400 22%) 0.3087\n",
      "7m 27s (- 25m 53s) (18600 22%) 0.2716\n",
      "7m 32s (- 25m 48s) (18800 22%) 0.2252\n",
      "7m 36s (- 25m 43s) (19000 22%) 0.2644\n",
      "7m 41s (- 25m 38s) (19200 23%) 0.2605\n",
      "7m 46s (- 25m 33s) (19400 23%) 0.2533\n",
      "7m 51s (- 25m 29s) (19600 23%) 0.2279\n",
      "7m 56s (- 25m 24s) (19800 23%) 0.2353\n",
      "8m 0s (- 25m 19s) (20000 24%) 0.2316\n",
      "8m 5s (- 25m 15s) (20200 24%) 0.2240\n",
      "8m 10s (- 25m 10s) (20400 24%) 0.2133\n",
      "8m 15s (- 25m 5s) (20600 24%) 0.2465\n",
      "8m 20s (- 25m 0s) (20800 25%) 0.2600\n",
      "8m 24s (- 24m 55s) (21000 25%) 0.2459\n",
      "8m 29s (- 24m 50s) (21200 25%) 0.3026\n",
      "8m 34s (- 24m 46s) (21400 25%) 0.2846\n",
      "8m 39s (- 24m 41s) (21600 25%) 0.2419\n",
      "8m 44s (- 24m 37s) (21800 26%) 0.2514\n",
      "8m 49s (- 24m 32s) (22000 26%) 0.2420\n",
      "8m 54s (- 24m 27s) (22200 26%) 0.2606\n",
      "8m 58s (- 24m 22s) (22400 26%) 0.2581\n",
      "9m 3s (- 24m 17s) (22600 27%) 0.2650\n",
      "9m 8s (- 24m 12s) (22800 27%) 0.3268\n",
      "9m 13s (- 24m 8s) (23000 27%) 0.2714\n",
      "9m 18s (- 24m 3s) (23200 27%) 0.2528\n",
      "9m 22s (- 23m 58s) (23400 28%) 0.2692\n",
      "9m 27s (- 23m 53s) (23600 28%) 0.2516\n",
      "9m 32s (- 23m 48s) (23800 28%) 0.2173\n",
      "9m 37s (- 23m 43s) (24000 28%) 0.2237\n",
      "9m 41s (- 23m 38s) (24200 29%) 0.3212\n",
      "9m 46s (- 23m 33s) (24400 29%) 0.2372\n",
      "9m 51s (- 23m 28s) (24600 29%) 0.2481\n",
      "9m 56s (- 23m 23s) (24800 29%) 0.2934\n",
      "10m 0s (- 23m 18s) (25000 30%) 0.3000\n",
      "10m 5s (- 23m 13s) (25200 30%) 0.2934\n",
      "10m 10s (- 23m 9s) (25400 30%) 0.2883\n",
      "10m 15s (- 23m 4s) (25600 30%) 0.2534\n",
      "10m 20s (- 22m 59s) (25800 31%) 0.3032\n",
      "10m 25s (- 22m 54s) (26000 31%) 0.2345\n",
      "10m 29s (- 22m 50s) (26200 31%) 0.2808\n",
      "10m 34s (- 22m 45s) (26400 31%) 0.2382\n",
      "10m 39s (- 22m 40s) (26600 31%) 0.2933\n",
      "10m 44s (- 22m 35s) (26800 32%) 0.2646\n",
      "10m 48s (- 22m 30s) (27000 32%) 0.2600\n",
      "10m 53s (- 22m 25s) (27200 32%) 0.2512\n",
      "10m 58s (- 22m 20s) (27400 32%) 0.2544\n",
      "11m 2s (- 22m 15s) (27600 33%) 0.2640\n",
      "11m 7s (- 22m 10s) (27800 33%) 0.2612\n",
      "11m 12s (- 22m 5s) (28000 33%) 0.2309\n",
      "11m 17s (- 22m 0s) (28200 33%) 0.2465\n",
      "11m 22s (- 21m 56s) (28400 34%) 0.2675\n",
      "11m 27s (- 21m 51s) (28600 34%) 0.2599\n",
      "11m 31s (- 21m 46s) (28800 34%) 0.2543\n",
      "11m 36s (- 21m 41s) (29000 34%) 0.2635\n",
      "11m 41s (- 21m 36s) (29200 35%) 0.2554\n",
      "11m 46s (- 21m 31s) (29400 35%) 0.2570\n",
      "11m 50s (- 21m 27s) (29600 35%) 0.2716\n",
      "11m 55s (- 21m 22s) (29800 35%) 0.2309\n",
      "12m 0s (- 21m 17s) (30000 36%) 0.2602\n",
      "12m 5s (- 21m 12s) (30200 36%) 0.2650\n",
      "12m 10s (- 21m 8s) (30400 36%) 0.2830\n",
      "12m 14s (- 21m 3s) (30600 36%) 0.3198\n",
      "12m 19s (- 20m 58s) (30800 37%) 0.2483\n",
      "12m 24s (- 20m 53s) (31000 37%) 0.2644\n",
      "12m 29s (- 20m 48s) (31200 37%) 0.3056\n",
      "12m 33s (- 20m 43s) (31400 37%) 0.2439\n",
      "12m 38s (- 20m 39s) (31600 37%) 0.2188\n",
      "12m 43s (- 20m 34s) (31800 38%) 0.2596\n",
      "12m 48s (- 20m 29s) (32000 38%) 0.2489\n",
      "12m 53s (- 20m 24s) (32200 38%) 0.2773\n",
      "12m 58s (- 20m 20s) (32400 38%) 0.2735\n",
      "13m 3s (- 20m 15s) (32600 39%) 0.2939\n",
      "13m 7s (- 20m 10s) (32800 39%) 0.2806\n",
      "13m 12s (- 20m 5s) (33000 39%) 0.2903\n",
      "13m 17s (- 20m 1s) (33200 39%) 0.2873\n",
      "13m 22s (- 19m 56s) (33400 40%) 0.3303\n",
      "13m 27s (- 19m 51s) (33600 40%) 0.2817\n",
      "13m 31s (- 19m 46s) (33800 40%) 0.2866\n",
      "13m 36s (- 19m 41s) (34000 40%) 0.2759\n",
      "13m 41s (- 19m 36s) (34200 41%) 0.2421\n",
      "13m 46s (- 19m 31s) (34400 41%) 0.2559\n",
      "13m 50s (- 19m 26s) (34600 41%) 0.2438\n",
      "13m 55s (- 19m 22s) (34800 41%) 0.2189\n",
      "14m 0s (- 19m 16s) (35000 42%) 0.2833\n",
      "14m 5s (- 19m 12s) (35200 42%) 0.2517\n",
      "14m 9s (- 19m 7s) (35400 42%) 0.2739\n",
      "14m 14s (- 19m 2s) (35600 42%) 0.2538\n",
      "14m 19s (- 18m 57s) (35800 43%) 0.2752\n",
      "14m 24s (- 18m 53s) (36000 43%) 0.2522\n",
      "14m 29s (- 18m 48s) (36200 43%) 0.3012\n",
      "14m 33s (- 18m 43s) (36400 43%) 0.2572\n",
      "14m 38s (- 18m 38s) (36600 43%) 0.2701\n",
      "14m 43s (- 18m 34s) (36800 44%) 0.2660\n",
      "14m 48s (- 18m 29s) (37000 44%) 0.2403\n",
      "14m 53s (- 18m 24s) (37200 44%) 0.2248\n",
      "14m 58s (- 18m 19s) (37400 44%) 0.2362\n",
      "15m 2s (- 18m 14s) (37600 45%) 0.2705\n",
      "15m 7s (- 18m 10s) (37800 45%) 0.2497\n",
      "15m 12s (- 18m 5s) (38000 45%) 0.2744\n",
      "15m 17s (- 18m 0s) (38200 45%) 0.2749\n",
      "15m 22s (- 17m 55s) (38400 46%) 0.2962\n",
      "15m 26s (- 17m 50s) (38600 46%) 0.2841\n",
      "15m 31s (- 17m 45s) (38800 46%) 0.2659\n",
      "15m 36s (- 17m 40s) (39000 46%) 0.2648\n",
      "15m 41s (- 17m 36s) (39200 47%) 0.2445\n",
      "15m 45s (- 17m 31s) (39400 47%) 0.2228\n",
      "15m 50s (- 17m 26s) (39600 47%) 0.2869\n",
      "15m 55s (- 17m 21s) (39800 47%) 0.2757\n",
      "15m 59s (- 17m 16s) (40000 48%) 0.2484\n",
      "16m 4s (- 17m 11s) (40200 48%) 0.2652\n",
      "16m 9s (- 17m 6s) (40400 48%) 0.2546\n",
      "16m 14s (- 17m 2s) (40600 48%) 0.2714\n",
      "16m 19s (- 16m 57s) (40800 49%) 0.2164\n",
      "16m 23s (- 16m 52s) (41000 49%) 0.2878\n",
      "16m 28s (- 16m 47s) (41200 49%) 0.2488\n",
      "16m 33s (- 16m 42s) (41400 49%) 0.2720\n",
      "16m 38s (- 16m 38s) (41600 50%) 0.2533\n",
      "16m 43s (- 16m 33s) (41800 50%) 0.2567\n",
      "16m 47s (- 16m 28s) (42000 50%) 0.2336\n",
      "16m 52s (- 16m 23s) (42200 50%) 0.2725\n",
      "16m 57s (- 16m 18s) (42400 50%) 0.2965\n",
      "17m 2s (- 16m 13s) (42600 51%) 0.2500\n",
      "17m 6s (- 16m 9s) (42800 51%) 0.2503\n",
      "17m 11s (- 16m 4s) (43000 51%) 0.2347\n",
      "17m 16s (- 15m 59s) (43200 51%) 0.2611\n",
      "17m 21s (- 15m 54s) (43400 52%) 0.2687\n",
      "17m 25s (- 15m 49s) (43600 52%) 0.2261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17m 30s (- 15m 44s) (43800 52%) 0.2695\n",
      "17m 35s (- 15m 40s) (44000 52%) 0.2631\n",
      "17m 39s (- 15m 35s) (44200 53%) 0.2350\n",
      "17m 44s (- 15m 30s) (44400 53%) 0.2834\n",
      "17m 49s (- 15m 25s) (44600 53%) 0.2368\n",
      "17m 54s (- 15m 20s) (44800 53%) 0.2495\n",
      "17m 59s (- 15m 16s) (45000 54%) 0.2500\n",
      "18m 4s (- 15m 11s) (45200 54%) 0.2609\n",
      "18m 8s (- 15m 6s) (45400 54%) 0.2595\n",
      "18m 13s (- 15m 1s) (45600 54%) 0.2519\n",
      "18m 18s (- 14m 57s) (45800 55%) 0.2545\n",
      "18m 23s (- 14m 52s) (46000 55%) 0.2945\n",
      "18m 28s (- 14m 47s) (46200 55%) 0.2553\n",
      "18m 32s (- 14m 42s) (46400 55%) 0.2412\n",
      "18m 37s (- 14m 37s) (46600 56%) 0.2608\n",
      "18m 42s (- 14m 32s) (46800 56%) 0.2877\n",
      "18m 47s (- 14m 28s) (47000 56%) 0.2636\n",
      "18m 52s (- 14m 23s) (47200 56%) 0.2180\n",
      "18m 56s (- 14m 18s) (47400 56%) 0.2917\n",
      "19m 1s (- 14m 13s) (47600 57%) 0.2091\n",
      "19m 6s (- 14m 8s) (47800 57%) 0.2604\n",
      "19m 11s (- 14m 4s) (48000 57%) 0.2422\n",
      "19m 16s (- 13m 59s) (48200 57%) 0.2564\n",
      "19m 21s (- 13m 54s) (48400 58%) 0.2626\n",
      "19m 25s (- 13m 49s) (48600 58%) 0.2006\n",
      "19m 30s (- 13m 44s) (48800 58%) 0.1978\n",
      "19m 35s (- 13m 40s) (49000 58%) 0.2561\n",
      "19m 39s (- 13m 35s) (49200 59%) 0.2609\n",
      "19m 44s (- 13m 30s) (49400 59%) 0.2421\n",
      "19m 49s (- 13m 25s) (49600 59%) 0.2801\n",
      "19m 54s (- 13m 20s) (49800 59%) 0.2924\n",
      "19m 58s (- 13m 15s) (50000 60%) 0.2677\n",
      "20m 3s (- 13m 11s) (50200 60%) 0.2614\n",
      "20m 8s (- 13m 6s) (50400 60%) 0.2920\n",
      "20m 12s (- 13m 1s) (50600 60%) 0.2485\n",
      "20m 17s (- 12m 56s) (50800 61%) 0.2622\n",
      "20m 22s (- 12m 51s) (51000 61%) 0.2395\n",
      "20m 27s (- 12m 46s) (51200 61%) 0.2535\n",
      "20m 32s (- 12m 42s) (51400 61%) 0.2454\n",
      "20m 37s (- 12m 37s) (51600 62%) 0.2857\n",
      "20m 41s (- 12m 32s) (51800 62%) 0.2319\n",
      "20m 46s (- 12m 27s) (52000 62%) 0.2189\n",
      "20m 51s (- 12m 23s) (52200 62%) 0.2424\n",
      "20m 56s (- 12m 18s) (52400 62%) 0.2394\n",
      "21m 1s (- 12m 13s) (52600 63%) 0.2668\n",
      "21m 5s (- 12m 8s) (52800 63%) 0.2177\n",
      "21m 10s (- 12m 3s) (53000 63%) 0.2393\n",
      "21m 15s (- 11m 59s) (53200 63%) 0.2369\n",
      "21m 20s (- 11m 54s) (53400 64%) 0.2733\n",
      "21m 25s (- 11m 49s) (53600 64%) 0.2326\n",
      "21m 29s (- 11m 44s) (53800 64%) 0.2420\n",
      "21m 34s (- 11m 39s) (54000 64%) 0.2392\n",
      "21m 39s (- 11m 35s) (54200 65%) 0.2404\n",
      "21m 44s (- 11m 30s) (54400 65%) 0.2659\n",
      "21m 48s (- 11m 25s) (54600 65%) 0.1787\n",
      "21m 53s (- 11m 20s) (54800 65%) 0.2341\n",
      "21m 58s (- 11m 15s) (55000 66%) 0.2686\n",
      "22m 2s (- 11m 10s) (55200 66%) 0.2673\n",
      "22m 7s (- 11m 6s) (55400 66%) 0.2975\n",
      "22m 12s (- 11m 1s) (55600 66%) 0.2150\n",
      "22m 17s (- 10m 56s) (55800 67%) 0.2481\n",
      "22m 21s (- 10m 51s) (56000 67%) 0.2408\n",
      "22m 26s (- 10m 46s) (56200 67%) 0.2366\n",
      "22m 31s (- 10m 42s) (56400 67%) 0.2721\n",
      "22m 36s (- 10m 37s) (56600 68%) 0.2406\n",
      "22m 41s (- 10m 32s) (56800 68%) 0.2809\n",
      "22m 46s (- 10m 27s) (57000 68%) 0.2721\n",
      "22m 51s (- 10m 23s) (57200 68%) 0.2474\n",
      "22m 55s (- 10m 18s) (57400 68%) 0.2784\n",
      "23m 0s (- 10m 13s) (57600 69%) 0.2685\n",
      "23m 5s (- 10m 8s) (57800 69%) 0.2324\n",
      "23m 10s (- 10m 3s) (58000 69%) 0.2247\n",
      "23m 14s (- 9m 59s) (58200 69%) 0.2711\n",
      "23m 19s (- 9m 54s) (58400 70%) 0.2401\n",
      "23m 24s (- 9m 49s) (58600 70%) 0.2413\n",
      "23m 29s (- 9m 44s) (58800 70%) 0.2618\n",
      "23m 34s (- 9m 39s) (59000 70%) 0.2446\n",
      "23m 39s (- 9m 35s) (59200 71%) 0.2457\n",
      "23m 43s (- 9m 30s) (59400 71%) 0.2897\n",
      "23m 48s (- 9m 25s) (59600 71%) 0.2548\n",
      "23m 53s (- 9m 20s) (59800 71%) 0.2641\n",
      "23m 58s (- 9m 15s) (60000 72%) 0.2859\n",
      "24m 2s (- 9m 11s) (60200 72%) 0.2778\n",
      "24m 7s (- 9m 6s) (60400 72%) 0.2715\n",
      "24m 12s (- 9m 1s) (60600 72%) 0.2493\n",
      "24m 17s (- 8m 56s) (60800 73%) 0.2268\n",
      "24m 22s (- 8m 51s) (61000 73%) 0.2698\n",
      "24m 26s (- 8m 47s) (61200 73%) 0.2594\n",
      "24m 31s (- 8m 42s) (61400 73%) 0.2587\n",
      "24m 36s (- 8m 37s) (61600 74%) 0.2769\n",
      "24m 41s (- 8m 32s) (61800 74%) 0.2724\n",
      "24m 46s (- 8m 27s) (62000 74%) 0.2603\n",
      "24m 50s (- 8m 23s) (62200 74%) 0.2370\n",
      "24m 55s (- 8m 18s) (62400 75%) 0.2546\n",
      "25m 0s (- 8m 13s) (62600 75%) 0.2772\n",
      "25m 5s (- 8m 8s) (62800 75%) 0.2552\n",
      "25m 10s (- 8m 4s) (63000 75%) 0.2113\n",
      "25m 14s (- 7m 59s) (63200 75%) 0.2142\n",
      "25m 19s (- 7m 54s) (63400 76%) 0.2123\n",
      "25m 24s (- 7m 49s) (63600 76%) 0.2704\n",
      "25m 29s (- 7m 44s) (63800 76%) 0.2640\n",
      "25m 33s (- 7m 40s) (64000 76%) 0.2480\n",
      "25m 38s (- 7m 35s) (64200 77%) 0.2365\n",
      "25m 43s (- 7m 30s) (64400 77%) 0.2793\n",
      "25m 48s (- 7m 25s) (64600 77%) 0.2752\n",
      "25m 53s (- 7m 20s) (64800 77%) 0.2351\n",
      "25m 57s (- 7m 16s) (65000 78%) 0.2706\n",
      "26m 2s (- 7m 11s) (65200 78%) 0.2175\n",
      "26m 7s (- 7m 6s) (65400 78%) 0.2654\n",
      "26m 12s (- 7m 1s) (65600 78%) 0.2773\n",
      "26m 16s (- 6m 56s) (65800 79%) 0.2689\n",
      "26m 21s (- 6m 52s) (66000 79%) 0.1904\n",
      "26m 26s (- 6m 47s) (66200 79%) 0.2737\n",
      "26m 31s (- 6m 42s) (66400 79%) 0.2527\n",
      "26m 36s (- 6m 37s) (66600 80%) 0.2639\n",
      "26m 41s (- 6m 32s) (66800 80%) 0.2353\n",
      "26m 45s (- 6m 28s) (67000 80%) 0.2173\n",
      "26m 50s (- 6m 23s) (67200 80%) 0.2455\n",
      "26m 55s (- 6m 18s) (67400 81%) 0.2347\n",
      "27m 0s (- 6m 13s) (67600 81%) 0.2405\n",
      "27m 4s (- 6m 8s) (67800 81%) 0.2067\n",
      "27m 9s (- 6m 4s) (68000 81%) 0.2590\n",
      "27m 14s (- 5m 59s) (68200 81%) 0.2274\n",
      "27m 19s (- 5m 54s) (68400 82%) 0.2065\n",
      "27m 23s (- 5m 49s) (68600 82%) 0.2680\n",
      "27m 28s (- 5m 44s) (68800 82%) 0.2427\n",
      "27m 33s (- 5m 40s) (69000 82%) 0.2062\n",
      "27m 38s (- 5m 35s) (69200 83%) 0.2473\n",
      "27m 42s (- 5m 30s) (69400 83%) 0.2783\n",
      "27m 47s (- 5m 25s) (69600 83%) 0.2351\n",
      "27m 52s (- 5m 20s) (69800 83%) 0.2623\n",
      "27m 57s (- 5m 16s) (70000 84%) 0.2597\n",
      "28m 2s (- 5m 11s) (70200 84%) 0.2010\n",
      "28m 6s (- 5m 6s) (70400 84%) 0.2347\n",
      "28m 11s (- 5m 1s) (70600 84%) 0.2911\n",
      "28m 16s (- 4m 56s) (70800 85%) 0.2678\n",
      "28m 21s (- 4m 52s) (71000 85%) 0.2412\n",
      "28m 25s (- 4m 47s) (71200 85%) 0.2834\n",
      "28m 30s (- 4m 42s) (71400 85%) 0.2714\n",
      "28m 35s (- 4m 37s) (71600 86%) 0.2527\n",
      "28m 40s (- 4m 33s) (71800 86%) 0.2711\n",
      "28m 45s (- 4m 28s) (72000 86%) 0.3093\n",
      "28m 50s (- 4m 23s) (72200 86%) 0.2433\n",
      "28m 54s (- 4m 18s) (72400 87%) 0.2496\n",
      "28m 59s (- 4m 13s) (72600 87%) 0.2716\n",
      "29m 4s (- 4m 9s) (72800 87%) 0.2296\n",
      "29m 9s (- 4m 4s) (73000 87%) 0.2495\n",
      "29m 14s (- 3m 59s) (73200 87%) 0.2560\n",
      "29m 18s (- 3m 54s) (73400 88%) 0.2280\n",
      "29m 23s (- 3m 49s) (73600 88%) 0.2480\n",
      "29m 28s (- 3m 45s) (73800 88%) 0.2417\n",
      "29m 33s (- 3m 40s) (74000 88%) 0.2536\n",
      "29m 38s (- 3m 35s) (74200 89%) 0.2597\n",
      "29m 42s (- 3m 30s) (74400 89%) 0.2078\n",
      "29m 47s (- 3m 25s) (74600 89%) 0.2560\n",
      "29m 52s (- 3m 21s) (74800 89%) 0.2441\n",
      "29m 57s (- 3m 16s) (75000 90%) 0.2951\n",
      "30m 2s (- 3m 11s) (75200 90%) 0.2485\n",
      "30m 6s (- 3m 6s) (75400 90%) 0.1970\n",
      "30m 11s (- 3m 1s) (75600 90%) 0.2339\n",
      "30m 16s (- 2m 57s) (75800 91%) 0.2949\n",
      "30m 21s (- 2m 52s) (76000 91%) 0.2324\n",
      "30m 25s (- 2m 47s) (76200 91%) 0.2045\n",
      "30m 30s (- 2m 42s) (76400 91%) 0.2146\n",
      "30m 35s (- 2m 37s) (76600 92%) 0.2678\n",
      "30m 39s (- 2m 33s) (76800 92%) 0.2514\n",
      "30m 44s (- 2m 28s) (77000 92%) 0.2911\n",
      "30m 49s (- 2m 23s) (77200 92%) 0.2621\n",
      "30m 53s (- 2m 18s) (77400 93%) 0.2202\n",
      "30m 58s (- 2m 13s) (77600 93%) 0.2541\n",
      "31m 3s (- 2m 9s) (77800 93%) 0.2406\n",
      "31m 8s (- 2m 4s) (78000 93%) 0.2625\n",
      "31m 12s (- 1m 59s) (78200 93%) 0.2427\n",
      "31m 17s (- 1m 54s) (78400 94%) 0.2737\n",
      "31m 22s (- 1m 50s) (78600 94%) 0.2597\n",
      "31m 27s (- 1m 45s) (78800 94%) 0.2685\n",
      "31m 32s (- 1m 40s) (79000 94%) 0.2282\n",
      "31m 36s (- 1m 35s) (79200 95%) 0.2455\n",
      "31m 41s (- 1m 30s) (79400 95%) 0.2478\n",
      "31m 46s (- 1m 26s) (79600 95%) 0.2222\n",
      "31m 51s (- 1m 21s) (79800 95%) 0.2154\n",
      "31m 55s (- 1m 16s) (80000 96%) 0.1967\n",
      "32m 0s (- 1m 11s) (80200 96%) 0.2632\n",
      "32m 5s (- 1m 6s) (80400 96%) 0.2165\n",
      "32m 10s (- 1m 2s) (80600 96%) 0.2280\n",
      "32m 15s (- 0m 57s) (80800 97%) 0.2689\n",
      "32m 19s (- 0m 52s) (81000 97%) 0.2422\n",
      "32m 24s (- 0m 47s) (81200 97%) 0.2457\n",
      "32m 29s (- 0m 42s) (81400 97%) 0.2831\n",
      "32m 34s (- 0m 38s) (81600 98%) 0.2404\n",
      "32m 38s (- 0m 33s) (81800 98%) 0.2580\n",
      "32m 43s (- 0m 28s) (82000 98%) 0.2493\n",
      "32m 48s (- 0m 23s) (82200 98%) 0.2365\n",
      "32m 53s (- 0m 19s) (82400 99%) 0.2671\n",
      "32m 58s (- 0m 14s) (82600 99%) 0.2962\n",
      "33m 2s (- 0m 9s) (82800 99%) 0.2624\n",
      "33m 7s (- 0m 4s) (83000 99%) 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zedroman/anaconda3/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/zedroman/anaconda3/lib/python3.6/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 4s (- 34m 0s) (200 0%) 0.3326\n",
      "0m 9s (- 33m 18s) (400 0%) 0.2123\n",
      "0m 14s (- 33m 20s) (600 0%) 0.2878\n",
      "0m 19s (- 33m 8s) (800 0%) 0.2476\n",
      "0m 23s (- 32m 48s) (1000 1%) 0.2424\n",
      "0m 28s (- 32m 40s) (1200 1%) 0.2350\n",
      "0m 33s (- 32m 32s) (1400 1%) 0.2174\n",
      "0m 38s (- 32m 21s) (1600 1%) 0.2729\n",
      "0m 42s (- 32m 15s) (1800 2%) 0.2472\n",
      "0m 47s (- 32m 16s) (2000 2%) 0.2669\n",
      "0m 52s (- 32m 11s) (2200 2%) 0.2660\n",
      "0m 57s (- 32m 2s) (2400 2%) 0.2600\n",
      "1m 1s (- 32m 1s) (2600 3%) 0.2234\n",
      "1m 6s (- 31m 59s) (2800 3%) 0.2361\n",
      "1m 11s (- 31m 57s) (3000 3%) 0.2403\n",
      "1m 16s (- 31m 50s) (3200 3%) 0.2437\n",
      "1m 21s (- 31m 44s) (3400 4%) 0.2529\n",
      "1m 25s (- 31m 38s) (3600 4%) 0.2388\n",
      "1m 30s (- 31m 36s) (3800 4%) 0.2605\n",
      "1m 35s (- 31m 33s) (4000 4%) 0.2466\n",
      "1m 40s (- 31m 28s) (4200 5%) 0.2983\n",
      "1m 45s (- 31m 24s) (4400 5%) 0.2557\n",
      "1m 50s (- 31m 20s) (4600 5%) 0.2444\n",
      "1m 54s (- 31m 14s) (4800 5%) 0.2298\n",
      "1m 59s (- 31m 10s) (5000 6%) 0.2547\n",
      "2m 4s (- 31m 8s) (5200 6%) 0.2407\n",
      "2m 9s (- 31m 1s) (5400 6%) 0.2954\n",
      "2m 13s (- 30m 56s) (5600 6%) 0.2655\n",
      "2m 18s (- 30m 49s) (5800 6%) 0.2715\n",
      "2m 23s (- 30m 44s) (6000 7%) 0.2508\n",
      "2m 28s (- 30m 41s) (6200 7%) 0.2632\n",
      "2m 33s (- 30m 37s) (6400 7%) 0.2417\n",
      "2m 38s (- 30m 33s) (6600 7%) 0.2478\n",
      "2m 42s (- 30m 27s) (6800 8%) 0.2225\n",
      "2m 47s (- 30m 22s) (7000 8%) 0.2475\n",
      "2m 52s (- 30m 16s) (7200 8%) 0.2385\n",
      "2m 56s (- 30m 12s) (7400 8%) 0.2517\n",
      "3m 1s (- 30m 7s) (7600 9%) 0.2357\n",
      "3m 6s (- 30m 3s) (7800 9%) 0.2311\n",
      "3m 11s (- 29m 59s) (8000 9%) 0.2081\n",
      "3m 16s (- 29m 54s) (8200 9%) 0.2469\n",
      "3m 20s (- 29m 49s) (8400 10%) 0.2214\n",
      "3m 25s (- 29m 43s) (8600 10%) 0.3010\n",
      "3m 30s (- 29m 38s) (8800 10%) 0.2423\n",
      "3m 35s (- 29m 34s) (9000 10%) 0.2233\n",
      "3m 40s (- 29m 29s) (9200 11%) 0.2523\n",
      "3m 44s (- 29m 24s) (9400 11%) 0.2525\n",
      "3m 49s (- 29m 20s) (9600 11%) 0.2491\n",
      "3m 54s (- 29m 15s) (9800 11%) 0.2547\n",
      "3m 59s (- 29m 9s) (10000 12%) 0.2168\n",
      "4m 4s (- 29m 6s) (10200 12%) 0.2239\n",
      "4m 8s (- 29m 1s) (10400 12%) 0.2249\n",
      "4m 13s (- 28m 55s) (10600 12%) 0.2712\n",
      "4m 18s (- 28m 51s) (10800 12%) 0.2485\n",
      "4m 23s (- 28m 47s) (11000 13%) 0.2354\n",
      "4m 27s (- 28m 42s) (11200 13%) 0.2284\n",
      "4m 32s (- 28m 38s) (11400 13%) 0.2287\n",
      "4m 37s (- 28m 33s) (11600 13%) 0.2459\n",
      "4m 42s (- 28m 29s) (11800 14%) 0.2541\n",
      "4m 47s (- 28m 24s) (12000 14%) 0.2232\n",
      "4m 51s (- 28m 18s) (12200 14%) 0.2898\n",
      "4m 56s (- 28m 14s) (12400 14%) 0.2445\n",
      "5m 1s (- 28m 9s) (12600 15%) 0.2213\n",
      "5m 6s (- 28m 4s) (12800 15%) 0.2911\n",
      "5m 11s (- 27m 59s) (13000 15%) 0.2155\n",
      "5m 15s (- 27m 54s) (13200 15%) 0.2436\n",
      "5m 20s (- 27m 48s) (13400 16%) 0.2382\n",
      "5m 25s (- 27m 44s) (13600 16%) 0.2913\n",
      "5m 29s (- 27m 39s) (13800 16%) 0.2387\n",
      "5m 34s (- 27m 33s) (14000 16%) 0.2162\n",
      "5m 39s (- 27m 28s) (14200 17%) 0.2421\n",
      "5m 44s (- 27m 23s) (14400 17%) 0.2234\n",
      "5m 48s (- 27m 19s) (14600 17%) 0.2496\n",
      "5m 53s (- 27m 13s) (14800 17%) 0.2495\n",
      "5m 58s (- 27m 8s) (15000 18%) 0.2584\n",
      "6m 3s (- 27m 4s) (15200 18%) 0.2686\n",
      "6m 7s (- 26m 59s) (15400 18%) 0.2541\n",
      "6m 12s (- 26m 55s) (15600 18%) 0.2429\n",
      "6m 17s (- 26m 50s) (15800 18%) 0.2325\n",
      "6m 22s (- 26m 45s) (16000 19%) 0.2337\n",
      "6m 27s (- 26m 40s) (16200 19%) 0.2775\n",
      "6m 31s (- 26m 36s) (16400 19%) 0.2326\n",
      "6m 36s (- 26m 31s) (16600 19%) 0.2599\n",
      "6m 41s (- 26m 25s) (16800 20%) 0.2463\n",
      "6m 45s (- 26m 20s) (17000 20%) 0.2311\n",
      "6m 50s (- 26m 14s) (17200 20%) 0.2596\n",
      "6m 55s (- 26m 9s) (17400 20%) 0.2058\n",
      "6m 59s (- 26m 4s) (17600 21%) 0.2649\n",
      "7m 4s (- 26m 0s) (17800 21%) 0.2749\n",
      "7m 9s (- 25m 55s) (18000 21%) 0.2304\n",
      "7m 14s (- 25m 50s) (18200 21%) 0.2128\n",
      "7m 18s (- 25m 45s) (18400 22%) 0.2743\n",
      "7m 23s (- 25m 40s) (18600 22%) 0.2923\n",
      "7m 28s (- 25m 36s) (18800 22%) 0.2465\n",
      "7m 33s (- 25m 31s) (19000 22%) 0.2316\n",
      "7m 38s (- 25m 27s) (19200 23%) 0.2085\n",
      "7m 43s (- 25m 22s) (19400 23%) 0.2257\n",
      "7m 47s (- 25m 17s) (19600 23%) 0.2397\n",
      "7m 52s (- 25m 12s) (19800 23%) 0.2348\n",
      "7m 57s (- 25m 7s) (20000 24%) 0.2457\n",
      "8m 2s (- 25m 3s) (20200 24%) 0.2555\n",
      "8m 6s (- 24m 58s) (20400 24%) 0.2610\n",
      "8m 11s (- 24m 54s) (20600 24%) 0.2323\n",
      "8m 16s (- 24m 49s) (20800 25%) 0.2289\n",
      "8m 21s (- 24m 44s) (21000 25%) 0.2280\n",
      "8m 26s (- 24m 39s) (21200 25%) 0.2445\n",
      "8m 30s (- 24m 34s) (21400 25%) 0.2145\n",
      "8m 35s (- 24m 29s) (21600 25%) 0.2968\n",
      "8m 40s (- 24m 24s) (21800 26%) 0.2710\n",
      "8m 44s (- 24m 19s) (22000 26%) 0.2533\n",
      "8m 49s (- 24m 15s) (22200 26%) 0.2521\n",
      "8m 54s (- 24m 10s) (22400 26%) 0.2174\n",
      "8m 59s (- 24m 5s) (22600 27%) 0.2357\n",
      "9m 3s (- 24m 0s) (22800 27%) 0.2702\n",
      "9m 8s (- 23m 56s) (23000 27%) 0.2446\n",
      "9m 13s (- 23m 51s) (23200 27%) 0.2594\n",
      "9m 18s (- 23m 46s) (23400 28%) 0.2629\n",
      "9m 22s (- 23m 41s) (23600 28%) 0.2260\n",
      "9m 27s (- 23m 36s) (23800 28%) 0.2479\n",
      "9m 32s (- 23m 31s) (24000 28%) 0.2186\n",
      "9m 36s (- 23m 26s) (24200 29%) 0.2640\n",
      "9m 41s (- 23m 21s) (24400 29%) 0.2711\n",
      "9m 46s (- 23m 16s) (24600 29%) 0.1999\n",
      "9m 51s (- 23m 11s) (24800 29%) 0.2659\n",
      "9m 55s (- 23m 7s) (25000 30%) 0.2246\n",
      "10m 0s (- 23m 2s) (25200 30%) 0.2298\n",
      "10m 5s (- 22m 57s) (25400 30%) 0.2735\n",
      "10m 10s (- 22m 52s) (25600 30%) 0.2927\n",
      "10m 14s (- 22m 47s) (25800 31%) 0.2428\n",
      "10m 19s (- 22m 42s) (26000 31%) 0.2344\n",
      "10m 24s (- 22m 38s) (26200 31%) 0.2638\n",
      "10m 29s (- 22m 33s) (26400 31%) 0.2560\n",
      "10m 33s (- 22m 28s) (26600 31%) 0.2420\n",
      "10m 38s (- 22m 23s) (26800 32%) 0.2649\n",
      "10m 43s (- 22m 19s) (27000 32%) 0.2130\n",
      "10m 48s (- 22m 14s) (27200 32%) 0.2425\n",
      "10m 52s (- 22m 9s) (27400 32%) 0.2445\n",
      "10m 57s (- 22m 4s) (27600 33%) 0.2693\n",
      "11m 2s (- 22m 0s) (27800 33%) 0.2580\n",
      "11m 7s (- 21m 55s) (28000 33%) 0.2450\n",
      "11m 11s (- 21m 50s) (28200 33%) 0.1756\n",
      "11m 16s (- 21m 45s) (28400 34%) 0.2045\n",
      "11m 21s (- 21m 40s) (28600 34%) 0.2144\n",
      "11m 26s (- 21m 35s) (28800 34%) 0.2243\n",
      "11m 30s (- 21m 31s) (29000 34%) 0.2581\n",
      "11m 35s (- 21m 26s) (29200 35%) 0.2779\n",
      "11m 40s (- 21m 21s) (29400 35%) 0.2431\n",
      "11m 45s (- 21m 16s) (29600 35%) 0.2606\n",
      "11m 49s (- 21m 11s) (29800 35%) 0.2436\n",
      "11m 54s (- 21m 7s) (30000 36%) 0.2290\n",
      "11m 59s (- 21m 2s) (30200 36%) 0.2625\n",
      "12m 4s (- 20m 57s) (30400 36%) 0.2266\n",
      "12m 8s (- 20m 52s) (30600 36%) 0.2359\n",
      "12m 13s (- 20m 48s) (30800 37%) 0.2518\n",
      "12m 18s (- 20m 43s) (31000 37%) 0.2665\n",
      "12m 23s (- 20m 38s) (31200 37%) 0.2184\n",
      "12m 27s (- 20m 33s) (31400 37%) 0.2178\n",
      "12m 32s (- 20m 28s) (31600 37%) 0.2607\n",
      "12m 37s (- 20m 23s) (31800 38%) 0.2318\n",
      "12m 42s (- 20m 19s) (32000 38%) 0.2714\n",
      "12m 46s (- 20m 14s) (32200 38%) 0.2939\n",
      "12m 51s (- 20m 9s) (32400 38%) 0.2492\n",
      "12m 56s (- 20m 5s) (32600 39%) 0.2227\n",
      "13m 1s (- 20m 0s) (32800 39%) 0.2304\n",
      "13m 5s (- 19m 55s) (33000 39%) 0.2425\n",
      "13m 10s (- 19m 50s) (33200 39%) 0.2243\n",
      "13m 15s (- 19m 46s) (33400 40%) 0.2331\n",
      "13m 20s (- 19m 41s) (33600 40%) 0.2640\n",
      "13m 24s (- 19m 36s) (33800 40%) 0.2327\n",
      "13m 29s (- 19m 31s) (34000 40%) 0.2284\n",
      "13m 34s (- 19m 26s) (34200 41%) 0.2058\n",
      "13m 39s (- 19m 22s) (34400 41%) 0.2388\n",
      "13m 44s (- 19m 17s) (34600 41%) 0.2530\n",
      "13m 49s (- 19m 12s) (34800 41%) 0.2191\n",
      "13m 53s (- 19m 8s) (35000 42%) 0.2438\n",
      "13m 58s (- 19m 3s) (35200 42%) 0.2440\n",
      "14m 3s (- 18m 58s) (35400 42%) 0.2087\n",
      "14m 8s (- 18m 53s) (35600 42%) 0.2636\n",
      "14m 12s (- 18m 49s) (35800 43%) 0.2007\n",
      "14m 17s (- 18m 44s) (36000 43%) 0.2449\n",
      "14m 22s (- 18m 39s) (36200 43%) 0.2409\n",
      "14m 27s (- 18m 34s) (36400 43%) 0.2372\n",
      "14m 31s (- 18m 29s) (36600 43%) 0.2246\n",
      "14m 36s (- 18m 25s) (36800 44%) 0.3008\n",
      "14m 41s (- 18m 20s) (37000 44%) 0.2033\n",
      "14m 46s (- 18m 15s) (37200 44%) 0.2143\n",
      "14m 50s (- 18m 10s) (37400 44%) 0.1830\n",
      "14m 55s (- 18m 6s) (37600 45%) 0.2679\n",
      "15m 0s (- 18m 1s) (37800 45%) 0.2515\n",
      "15m 5s (- 17m 56s) (38000 45%) 0.2659\n",
      "15m 9s (- 17m 51s) (38200 45%) 0.2176\n",
      "15m 14s (- 17m 47s) (38400 46%) 0.2404\n",
      "15m 19s (- 17m 42s) (38600 46%) 0.2585\n",
      "15m 24s (- 17m 37s) (38800 46%) 0.2468\n",
      "15m 29s (- 17m 32s) (39000 46%) 0.2358\n",
      "15m 33s (- 17m 27s) (39200 47%) 0.2335\n",
      "15m 38s (- 17m 23s) (39400 47%) 0.2207\n",
      "15m 43s (- 17m 18s) (39600 47%) 0.2302\n",
      "15m 48s (- 17m 13s) (39800 47%) 0.2790\n",
      "15m 53s (- 17m 9s) (40000 48%) 0.2511\n",
      "15m 57s (- 17m 4s) (40200 48%) 0.2349\n",
      "16m 2s (- 16m 59s) (40400 48%) 0.2649\n",
      "16m 7s (- 16m 54s) (40600 48%) 0.2022\n",
      "16m 12s (- 16m 50s) (40800 49%) 0.2666\n",
      "16m 17s (- 16m 45s) (41000 49%) 0.2260\n",
      "16m 21s (- 16m 40s) (41200 49%) 0.2904\n",
      "16m 26s (- 16m 35s) (41400 49%) 0.2359\n",
      "16m 31s (- 16m 31s) (41600 50%) 0.2676\n",
      "16m 36s (- 16m 26s) (41800 50%) 0.2512\n",
      "16m 41s (- 16m 22s) (42000 50%) 0.2334\n",
      "16m 46s (- 16m 17s) (42200 50%) 0.2251\n",
      "16m 50s (- 16m 12s) (42400 50%) 0.2494\n",
      "16m 55s (- 16m 7s) (42600 51%) 0.2294\n",
      "17m 0s (- 16m 3s) (42800 51%) 0.2281\n",
      "17m 5s (- 15m 58s) (43000 51%) 0.2859\n",
      "17m 10s (- 15m 53s) (43200 51%) 0.2573\n",
      "17m 15s (- 15m 49s) (43400 52%) 0.2307\n",
      "17m 19s (- 15m 44s) (43600 52%) 0.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17m 24s (- 15m 39s) (43800 52%) 0.2590\n",
      "17m 29s (- 15m 34s) (44000 52%) 0.2414\n",
      "17m 34s (- 15m 29s) (44200 53%) 0.2396\n",
      "17m 38s (- 15m 25s) (44400 53%) 0.2137\n",
      "17m 43s (- 15m 20s) (44600 53%) 0.2537\n",
      "17m 48s (- 15m 15s) (44800 53%) 0.2263\n",
      "17m 53s (- 15m 10s) (45000 54%) 0.2469\n",
      "17m 57s (- 15m 5s) (45200 54%) 0.2695\n",
      "18m 2s (- 15m 1s) (45400 54%) 0.2226\n",
      "18m 7s (- 14m 56s) (45600 54%) 0.2350\n",
      "18m 12s (- 14m 51s) (45800 55%) 0.2478\n",
      "18m 17s (- 14m 47s) (46000 55%) 0.2001\n",
      "18m 21s (- 14m 42s) (46200 55%) 0.2336\n",
      "18m 26s (- 14m 37s) (46400 55%) 0.2188\n",
      "18m 31s (- 14m 32s) (46600 56%) 0.2361\n",
      "18m 36s (- 14m 28s) (46800 56%) 0.2927\n",
      "18m 41s (- 14m 23s) (47000 56%) 0.2129\n",
      "18m 46s (- 14m 18s) (47200 56%) 0.2186\n",
      "18m 50s (- 14m 13s) (47400 56%) 0.2661\n",
      "18m 55s (- 14m 8s) (47600 57%) 0.2402\n",
      "19m 0s (- 14m 4s) (47800 57%) 0.2424\n",
      "19m 4s (- 13m 59s) (48000 57%) 0.2375\n",
      "19m 9s (- 13m 54s) (48200 57%) 0.2440\n",
      "19m 14s (- 13m 49s) (48400 58%) 0.2453\n",
      "19m 19s (- 13m 45s) (48600 58%) 0.2716\n",
      "19m 23s (- 13m 40s) (48800 58%) 0.2520\n",
      "19m 28s (- 13m 35s) (49000 58%) 0.2432\n",
      "19m 33s (- 13m 30s) (49200 59%) 0.2153\n",
      "19m 38s (- 13m 25s) (49400 59%) 0.2298\n",
      "19m 42s (- 13m 21s) (49600 59%) 0.2278\n",
      "19m 47s (- 13m 16s) (49800 59%) 0.1934\n",
      "19m 52s (- 13m 11s) (50000 60%) 0.2741\n",
      "19m 57s (- 13m 6s) (50200 60%) 0.2470\n",
      "20m 2s (- 13m 2s) (50400 60%) 0.2283\n",
      "20m 7s (- 12m 57s) (50600 60%) 0.2499\n",
      "20m 11s (- 12m 52s) (50800 61%) 0.1868\n",
      "20m 16s (- 12m 48s) (51000 61%) 0.2251\n",
      "20m 21s (- 12m 43s) (51200 61%) 0.2423\n",
      "20m 26s (- 12m 38s) (51400 61%) 0.2352\n",
      "20m 30s (- 12m 33s) (51600 62%) 0.2464\n",
      "20m 35s (- 12m 28s) (51800 62%) 0.2333\n",
      "20m 40s (- 12m 24s) (52000 62%) 0.2623\n",
      "20m 45s (- 12m 19s) (52200 62%) 0.2469\n",
      "20m 49s (- 12m 14s) (52400 62%) 0.2447\n",
      "20m 54s (- 12m 9s) (52600 63%) 0.2612\n",
      "20m 59s (- 12m 5s) (52800 63%) 0.2462\n",
      "21m 4s (- 12m 0s) (53000 63%) 0.2432\n",
      "21m 9s (- 11m 55s) (53200 63%) 0.2182\n",
      "21m 14s (- 11m 50s) (53400 64%) 0.2729\n",
      "21m 18s (- 11m 46s) (53600 64%) 0.2570\n",
      "21m 23s (- 11m 41s) (53800 64%) 0.2316\n",
      "21m 28s (- 11m 36s) (54000 64%) 0.2564\n",
      "21m 33s (- 11m 31s) (54200 65%) 0.2137\n",
      "21m 37s (- 11m 26s) (54400 65%) 0.2417\n",
      "21m 42s (- 11m 22s) (54600 65%) 0.1999\n",
      "21m 47s (- 11m 17s) (54800 65%) 0.1977\n",
      "21m 51s (- 11m 12s) (55000 66%) 0.2628\n",
      "21m 56s (- 11m 7s) (55200 66%) 0.2104\n",
      "22m 1s (- 11m 2s) (55400 66%) 0.2160\n",
      "22m 6s (- 10m 58s) (55600 66%) 0.2186\n",
      "22m 11s (- 10m 53s) (55800 67%) 0.2613\n",
      "22m 15s (- 10m 48s) (56000 67%) 0.2138\n",
      "22m 20s (- 10m 43s) (56200 67%) 0.2531\n",
      "22m 25s (- 10m 39s) (56400 67%) 0.2259\n",
      "22m 30s (- 10m 34s) (56600 68%) 0.2468\n",
      "22m 35s (- 10m 29s) (56800 68%) 0.2329\n",
      "22m 39s (- 10m 24s) (57000 68%) 0.2329\n",
      "22m 44s (- 10m 20s) (57200 68%) 0.2056\n",
      "22m 49s (- 10m 15s) (57400 68%) 0.2233\n",
      "22m 53s (- 10m 10s) (57600 69%) 0.2482\n",
      "22m 58s (- 10m 5s) (57800 69%) 0.2560\n",
      "23m 3s (- 10m 0s) (58000 69%) 0.2342\n",
      "23m 8s (- 9m 56s) (58200 69%) 0.2567\n",
      "23m 12s (- 9m 51s) (58400 70%) 0.2256\n",
      "23m 17s (- 9m 46s) (58600 70%) 0.2300\n",
      "23m 22s (- 9m 41s) (58800 70%) 0.2191\n",
      "23m 27s (- 9m 37s) (59000 70%) 0.2375\n",
      "23m 32s (- 9m 32s) (59200 71%) 0.2418\n",
      "23m 36s (- 9m 27s) (59400 71%) 0.2445\n",
      "23m 41s (- 9m 22s) (59600 71%) 0.2072\n",
      "23m 46s (- 9m 17s) (59800 71%) 0.2604\n",
      "23m 51s (- 9m 13s) (60000 72%) 0.2369\n",
      "23m 56s (- 9m 8s) (60200 72%) 0.2661\n",
      "24m 0s (- 9m 3s) (60400 72%) 0.2383\n",
      "24m 5s (- 8m 59s) (60600 72%) 0.1947\n",
      "24m 10s (- 8m 54s) (60800 73%) 0.2210\n",
      "24m 15s (- 8m 49s) (61000 73%) 0.2258\n",
      "24m 20s (- 8m 44s) (61200 73%) 0.2477\n",
      "24m 25s (- 8m 40s) (61400 73%) 0.1994\n",
      "24m 29s (- 8m 35s) (61600 74%) 0.2212\n",
      "24m 34s (- 8m 30s) (61800 74%) 0.2232\n",
      "24m 39s (- 8m 25s) (62000 74%) 0.3027\n",
      "24m 44s (- 8m 20s) (62200 74%) 0.2236\n",
      "24m 48s (- 8m 16s) (62400 75%) 0.2063\n",
      "24m 53s (- 8m 11s) (62600 75%) 0.2426\n",
      "24m 58s (- 8m 6s) (62800 75%) 0.2339\n",
      "25m 3s (- 8m 1s) (63000 75%) 0.2258\n",
      "25m 8s (- 7m 57s) (63200 75%) 0.2263\n",
      "25m 13s (- 7m 52s) (63400 76%) 0.2670\n",
      "25m 17s (- 7m 47s) (63600 76%) 0.2091\n",
      "25m 22s (- 7m 42s) (63800 76%) 0.1991\n",
      "25m 27s (- 7m 37s) (64000 76%) 0.2546\n",
      "25m 31s (- 7m 33s) (64200 77%) 0.2662\n",
      "25m 36s (- 7m 28s) (64400 77%) 0.2866\n",
      "25m 41s (- 7m 23s) (64600 77%) 0.2211\n",
      "25m 46s (- 7m 18s) (64800 77%) 0.2527\n",
      "25m 50s (- 7m 14s) (65000 78%) 0.2788\n",
      "25m 55s (- 7m 9s) (65200 78%) 0.2382\n",
      "26m 0s (- 7m 4s) (65400 78%) 0.2468\n",
      "26m 5s (- 6m 59s) (65600 78%) 0.2310\n",
      "26m 10s (- 6m 55s) (65800 79%) 0.2303\n",
      "26m 14s (- 6m 50s) (66000 79%) 0.2093\n",
      "26m 19s (- 6m 45s) (66200 79%) 0.2009\n",
      "26m 24s (- 6m 40s) (66400 79%) 0.2471\n",
      "26m 29s (- 6m 35s) (66600 80%) 0.2630\n",
      "26m 33s (- 6m 31s) (66800 80%) 0.2243\n",
      "26m 38s (- 6m 26s) (67000 80%) 0.2626\n",
      "26m 43s (- 6m 21s) (67200 80%) 0.2348\n",
      "26m 48s (- 6m 16s) (67400 81%) 0.2330\n",
      "26m 53s (- 6m 12s) (67600 81%) 0.2167\n",
      "26m 57s (- 6m 7s) (67800 81%) 0.2363\n",
      "27m 2s (- 6m 2s) (68000 81%) 0.2210\n",
      "27m 7s (- 5m 57s) (68200 81%) 0.2337\n",
      "27m 12s (- 5m 53s) (68400 82%) 0.2810\n",
      "27m 16s (- 5m 48s) (68600 82%) 0.2372\n",
      "27m 21s (- 5m 43s) (68800 82%) 0.2407\n",
      "27m 26s (- 5m 38s) (69000 82%) 0.2614\n",
      "27m 30s (- 5m 33s) (69200 83%) 0.2583\n",
      "27m 35s (- 5m 29s) (69400 83%) 0.2266\n",
      "27m 40s (- 5m 24s) (69600 83%) 0.2398\n",
      "27m 45s (- 5m 19s) (69800 83%) 0.2146\n",
      "27m 50s (- 5m 14s) (70000 84%) 0.2258\n",
      "27m 55s (- 5m 10s) (70200 84%) 0.2056\n",
      "27m 59s (- 5m 5s) (70400 84%) 0.2128\n",
      "28m 4s (- 5m 0s) (70600 84%) 0.2262\n",
      "28m 9s (- 4m 55s) (70800 85%) 0.2238\n",
      "28m 14s (- 4m 51s) (71000 85%) 0.2156\n",
      "28m 19s (- 4m 46s) (71200 85%) 0.1941\n",
      "28m 24s (- 4m 41s) (71400 85%) 0.2404\n",
      "28m 28s (- 4m 36s) (71600 86%) 0.2454\n",
      "28m 33s (- 4m 31s) (71800 86%) 0.2624\n",
      "28m 38s (- 4m 27s) (72000 86%) 0.2385\n",
      "28m 43s (- 4m 22s) (72200 86%) 0.2581\n",
      "28m 48s (- 4m 17s) (72400 87%) 0.2687\n",
      "28m 52s (- 4m 12s) (72600 87%) 0.2330\n",
      "28m 57s (- 4m 8s) (72800 87%) 0.2603\n",
      "29m 2s (- 4m 3s) (73000 87%) 0.2642\n",
      "29m 7s (- 3m 58s) (73200 87%) 0.2301\n",
      "29m 11s (- 3m 53s) (73400 88%) 0.2261\n",
      "29m 16s (- 3m 48s) (73600 88%) 0.2379\n",
      "29m 21s (- 3m 44s) (73800 88%) 0.2573\n",
      "29m 26s (- 3m 39s) (74000 88%) 0.2609\n",
      "29m 30s (- 3m 34s) (74200 89%) 0.2333\n",
      "29m 35s (- 3m 29s) (74400 89%) 0.2250\n",
      "29m 40s (- 3m 25s) (74600 89%) 0.2327\n",
      "29m 45s (- 3m 20s) (74800 89%) 0.2196\n",
      "29m 50s (- 3m 15s) (75000 90%) 0.2513\n",
      "29m 54s (- 3m 10s) (75200 90%) 0.2138\n",
      "29m 59s (- 3m 6s) (75400 90%) 0.1884\n",
      "30m 4s (- 3m 1s) (75600 90%) 0.2104\n",
      "30m 9s (- 2m 56s) (75800 91%) 0.2490\n",
      "30m 13s (- 2m 51s) (76000 91%) 0.2223\n",
      "30m 18s (- 2m 46s) (76200 91%) 0.2253\n",
      "30m 23s (- 2m 42s) (76400 91%) 0.2362\n",
      "30m 28s (- 2m 37s) (76600 92%) 0.2317\n",
      "30m 32s (- 2m 32s) (76800 92%) 0.1971\n",
      "30m 37s (- 2m 27s) (77000 92%) 0.2130\n",
      "30m 42s (- 2m 23s) (77200 92%) 0.2488\n",
      "30m 47s (- 2m 18s) (77400 93%) 0.2428\n",
      "30m 51s (- 2m 13s) (77600 93%) 0.2323\n",
      "30m 56s (- 2m 8s) (77800 93%) 0.2521\n",
      "31m 1s (- 2m 3s) (78000 93%) 0.2188\n",
      "31m 6s (- 1m 59s) (78200 93%) 0.2203\n",
      "31m 11s (- 1m 54s) (78400 94%) 0.2125\n",
      "31m 15s (- 1m 49s) (78600 94%) 0.2312\n",
      "31m 20s (- 1m 44s) (78800 94%) 0.2271\n",
      "31m 25s (- 1m 40s) (79000 94%) 0.2144\n",
      "31m 30s (- 1m 35s) (79200 95%) 0.2345\n",
      "31m 35s (- 1m 30s) (79400 95%) 0.2124\n",
      "31m 39s (- 1m 25s) (79600 95%) 0.2373\n",
      "31m 44s (- 1m 21s) (79800 95%) 0.2471\n",
      "31m 49s (- 1m 16s) (80000 96%) 0.2351\n",
      "31m 54s (- 1m 11s) (80200 96%) 0.1934\n",
      "31m 59s (- 1m 6s) (80400 96%) 0.1875\n",
      "32m 3s (- 1m 1s) (80600 96%) 0.2334\n",
      "32m 8s (- 0m 57s) (80800 97%) 0.2295\n",
      "32m 13s (- 0m 52s) (81000 97%) 0.2190\n",
      "32m 18s (- 0m 47s) (81200 97%) 0.2622\n",
      "32m 23s (- 0m 42s) (81400 97%) 0.2647\n",
      "32m 27s (- 0m 38s) (81600 98%) 0.2230\n",
      "32m 32s (- 0m 33s) (81800 98%) 0.2200\n",
      "32m 37s (- 0m 28s) (82000 98%) 0.2111\n",
      "32m 42s (- 0m 23s) (82200 98%) 0.2707\n",
      "32m 46s (- 0m 18s) (82400 99%) 0.2403\n",
      "32m 51s (- 0m 14s) (82600 99%) 0.1814\n",
      "32m 56s (- 0m 9s) (82800 99%) 0.2117\n",
      "33m 1s (- 0m 4s) (83000 99%) 0.2575\n",
      "0m 4s (- 33m 48s) (200 0%) 0.2286\n",
      "0m 9s (- 33m 59s) (400 0%) 0.2312\n",
      "0m 14s (- 33m 32s) (600 0%) 0.2232\n",
      "0m 19s (- 33m 27s) (800 0%) 0.2063\n",
      "0m 24s (- 33m 16s) (1000 1%) 0.2257\n",
      "0m 29s (- 33m 9s) (1200 1%) 0.1942\n",
      "0m 33s (- 32m 52s) (1400 1%) 0.2248\n",
      "0m 38s (- 32m 42s) (1600 1%) 0.2510\n",
      "0m 43s (- 32m 35s) (1800 2%) 0.2586\n",
      "0m 48s (- 32m 33s) (2000 2%) 0.2332\n",
      "0m 52s (- 32m 26s) (2200 2%) 0.2036\n",
      "0m 57s (- 32m 21s) (2400 2%) 0.2319\n",
      "1m 2s (- 32m 18s) (2600 3%) 0.2259\n",
      "1m 7s (- 32m 16s) (2800 3%) 0.2126\n",
      "1m 12s (- 32m 12s) (3000 3%) 0.2095\n",
      "1m 17s (- 32m 6s) (3200 3%) 0.2624\n",
      "1m 21s (- 32m 0s) (3400 4%) 0.2481\n",
      "1m 26s (- 31m 54s) (3600 4%) 0.2137\n",
      "1m 31s (- 31m 50s) (3800 4%) 0.2296\n",
      "1m 36s (- 31m 45s) (4000 4%) 0.2194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 40s (- 31m 39s) (4200 5%) 0.2536\n",
      "1m 45s (- 31m 35s) (4400 5%) 0.2377\n",
      "1m 50s (- 31m 29s) (4600 5%) 0.2214\n",
      "1m 55s (- 31m 25s) (4800 5%) 0.2479\n",
      "2m 0s (- 31m 18s) (5000 6%) 0.2225\n",
      "2m 4s (- 31m 13s) (5200 6%) 0.2476\n",
      "2m 9s (- 31m 9s) (5400 6%) 0.2178\n",
      "2m 14s (- 31m 5s) (5600 6%) 0.2387\n",
      "2m 19s (- 31m 0s) (5800 6%) 0.2095\n",
      "2m 24s (- 30m 55s) (6000 7%) 0.2690\n",
      "2m 28s (- 30m 48s) (6200 7%) 0.2186\n",
      "2m 33s (- 30m 42s) (6400 7%) 0.2144\n",
      "2m 38s (- 30m 36s) (6600 7%) 0.2373\n",
      "2m 43s (- 30m 31s) (6800 8%) 0.2211\n",
      "2m 47s (- 30m 27s) (7000 8%) 0.2106\n",
      "2m 52s (- 30m 23s) (7200 8%) 0.2084\n",
      "2m 57s (- 30m 20s) (7400 8%) 0.2277\n",
      "3m 2s (- 30m 14s) (7600 9%) 0.2104\n",
      "3m 7s (- 30m 9s) (7800 9%) 0.2003\n",
      "3m 11s (- 30m 4s) (8000 9%) 0.2432\n",
      "3m 16s (- 29m 58s) (8200 9%) 0.2255\n",
      "3m 21s (- 29m 55s) (8400 10%) 0.2558\n",
      "3m 26s (- 29m 50s) (8600 10%) 0.2082\n",
      "3m 31s (- 29m 46s) (8800 10%) 0.1985\n",
      "3m 36s (- 29m 41s) (9000 10%) 0.2189\n",
      "3m 40s (- 29m 37s) (9200 11%) 0.2282\n",
      "3m 45s (- 29m 32s) (9400 11%) 0.1946\n",
      "3m 50s (- 29m 26s) (9600 11%) 0.1800\n",
      "3m 55s (- 29m 23s) (9800 11%) 0.2207\n",
      "4m 0s (- 29m 18s) (10000 12%) 0.2331\n",
      "4m 5s (- 29m 13s) (10200 12%) 0.2366\n",
      "4m 9s (- 29m 9s) (10400 12%) 0.2537\n",
      "4m 14s (- 29m 3s) (10600 12%) 0.2337\n",
      "4m 19s (- 28m 59s) (10800 12%) 0.2861\n",
      "4m 24s (- 28m 54s) (11000 13%) 0.2238\n",
      "4m 29s (- 28m 50s) (11200 13%) 0.2268\n",
      "4m 34s (- 28m 45s) (11400 13%) 0.2069\n",
      "4m 38s (- 28m 41s) (11600 13%) 0.2340\n",
      "4m 43s (- 28m 37s) (11800 14%) 0.2352\n",
      "4m 48s (- 28m 30s) (12000 14%) 0.2126\n",
      "4m 53s (- 28m 25s) (12200 14%) 0.2153\n",
      "4m 57s (- 28m 20s) (12400 14%) 0.2399\n",
      "5m 2s (- 28m 15s) (12600 15%) 0.2465\n",
      "5m 7s (- 28m 9s) (12800 15%) 0.1873\n",
      "5m 12s (- 28m 5s) (13000 15%) 0.2028\n",
      "5m 16s (- 28m 0s) (13200 15%) 0.1959\n",
      "5m 21s (- 27m 54s) (13400 16%) 0.2105\n",
      "5m 26s (- 27m 49s) (13600 16%) 0.2474\n",
      "5m 31s (- 27m 44s) (13800 16%) 0.2037\n",
      "5m 35s (- 27m 39s) (14000 16%) 0.2192\n",
      "5m 40s (- 27m 33s) (14200 17%) 0.2097\n",
      "5m 45s (- 27m 29s) (14400 17%) 0.2394\n",
      "5m 49s (- 27m 24s) (14600 17%) 0.2342\n",
      "5m 54s (- 27m 19s) (14800 17%) 0.2125\n",
      "5m 59s (- 27m 14s) (15000 18%) 0.2277\n",
      "6m 4s (- 27m 9s) (15200 18%) 0.2298\n",
      "6m 9s (- 27m 5s) (15400 18%) 0.2552\n",
      "6m 13s (- 27m 0s) (15600 18%) 0.1883\n",
      "6m 18s (- 26m 55s) (15800 18%) 0.2374\n",
      "6m 23s (- 26m 50s) (16000 19%) 0.2054\n",
      "6m 28s (- 26m 46s) (16200 19%) 0.2235\n",
      "6m 33s (- 26m 41s) (16400 19%) 0.2040\n",
      "6m 38s (- 26m 37s) (16600 19%) 0.2188\n",
      "6m 42s (- 26m 31s) (16800 20%) 0.2237\n",
      "6m 47s (- 26m 26s) (17000 20%) 0.2655\n",
      "6m 52s (- 26m 21s) (17200 20%) 0.2252\n",
      "6m 57s (- 26m 17s) (17400 20%) 0.2356\n",
      "7m 1s (- 26m 12s) (17600 21%) 0.2095\n",
      "7m 6s (- 26m 7s) (17800 21%) 0.2186\n",
      "7m 11s (- 26m 2s) (18000 21%) 0.1948\n",
      "7m 16s (- 25m 58s) (18200 21%) 0.2514\n",
      "7m 21s (- 25m 53s) (18400 22%) 0.2285\n",
      "7m 25s (- 25m 48s) (18600 22%) 0.2330\n",
      "7m 30s (- 25m 44s) (18800 22%) 0.2537\n",
      "7m 35s (- 25m 39s) (19000 22%) 0.2258\n",
      "7m 40s (- 25m 34s) (19200 23%) 0.1966\n",
      "7m 45s (- 25m 29s) (19400 23%) 0.1827\n",
      "7m 49s (- 25m 24s) (19600 23%) 0.2126\n",
      "7m 54s (- 25m 19s) (19800 23%) 0.2268\n",
      "7m 59s (- 25m 14s) (20000 24%) 0.2258\n",
      "8m 4s (- 25m 9s) (20200 24%) 0.2150\n",
      "8m 8s (- 25m 4s) (20400 24%) 0.1929\n",
      "8m 13s (- 25m 0s) (20600 24%) 0.2451\n",
      "8m 18s (- 24m 55s) (20800 25%) 0.2882\n",
      "8m 23s (- 24m 50s) (21000 25%) 0.2714\n",
      "8m 27s (- 24m 45s) (21200 25%) 0.2291\n",
      "8m 32s (- 24m 40s) (21400 25%) 0.2225\n",
      "8m 37s (- 24m 35s) (21600 25%) 0.2565\n",
      "8m 42s (- 24m 30s) (21800 26%) 0.2031\n",
      "8m 46s (- 24m 25s) (22000 26%) 0.2255\n",
      "8m 51s (- 24m 20s) (22200 26%) 0.2063\n",
      "8m 56s (- 24m 16s) (22400 26%) 0.2044\n",
      "9m 1s (- 24m 11s) (22600 27%) 0.2445\n",
      "9m 6s (- 24m 6s) (22800 27%) 0.2052\n",
      "9m 10s (- 24m 2s) (23000 27%) 0.5575\n",
      "9m 15s (- 23m 57s) (23200 27%) 0.9499\n",
      "9m 20s (- 23m 52s) (23400 28%) 0.5788\n",
      "9m 25s (- 23m 47s) (23600 28%) 0.5095\n",
      "9m 30s (- 23m 42s) (23800 28%) 0.3947\n",
      "9m 34s (- 23m 38s) (24000 28%) 0.4186\n",
      "9m 39s (- 23m 33s) (24200 29%) 0.4131\n",
      "9m 44s (- 23m 28s) (24400 29%) 0.3882\n",
      "9m 49s (- 23m 23s) (24600 29%) 0.3799\n",
      "9m 54s (- 23m 19s) (24800 29%) 0.4273\n",
      "9m 59s (- 23m 14s) (25000 30%) 0.3595\n",
      "10m 3s (- 23m 9s) (25200 30%) 0.3604\n",
      "10m 8s (- 23m 5s) (25400 30%) 0.3734\n",
      "10m 13s (- 22m 59s) (25600 30%) 0.3317\n",
      "10m 18s (- 22m 55s) (25800 31%) 0.3690\n",
      "10m 22s (- 22m 49s) (26000 31%) 0.3524\n",
      "10m 27s (- 22m 44s) (26200 31%) 0.3432\n",
      "10m 32s (- 22m 39s) (26400 31%) 0.3428\n",
      "10m 36s (- 22m 35s) (26600 31%) 0.3509\n",
      "10m 41s (- 22m 30s) (26800 32%) 0.3467\n",
      "10m 46s (- 22m 25s) (27000 32%) 0.3378\n",
      "10m 51s (- 22m 20s) (27200 32%) 0.3409\n",
      "10m 56s (- 22m 15s) (27400 32%) 0.3379\n",
      "11m 0s (- 22m 11s) (27600 33%) 0.3117\n",
      "11m 5s (- 22m 6s) (27800 33%) 0.3002\n",
      "11m 10s (- 22m 1s) (28000 33%) 0.3165\n",
      "11m 15s (- 21m 57s) (28200 33%) 0.2997\n",
      "11m 20s (- 21m 52s) (28400 34%) 0.2889\n",
      "11m 24s (- 21m 47s) (28600 34%) 0.3199\n",
      "11m 29s (- 21m 43s) (28800 34%) 0.3067\n",
      "11m 34s (- 21m 38s) (29000 34%) 0.2683\n",
      "11m 39s (- 21m 33s) (29200 35%) 0.3115\n",
      "11m 44s (- 21m 29s) (29400 35%) 0.3093\n",
      "11m 49s (- 21m 24s) (29600 35%) 0.3571\n",
      "11m 54s (- 21m 19s) (29800 35%) 0.3073\n",
      "11m 58s (- 21m 14s) (30000 36%) 0.3063\n",
      "12m 3s (- 21m 9s) (30200 36%) 0.3199\n",
      "12m 8s (- 21m 5s) (30400 36%) 0.2651\n",
      "12m 13s (- 21m 0s) (30600 36%) 0.2658\n",
      "12m 17s (- 20m 55s) (30800 37%) 0.2871\n",
      "12m 22s (- 20m 50s) (31000 37%) 0.3444\n",
      "12m 27s (- 20m 45s) (31200 37%) 0.2350\n",
      "12m 32s (- 20m 40s) (31400 37%) 0.2719\n",
      "12m 36s (- 20m 35s) (31600 37%) 0.3206\n",
      "12m 41s (- 20m 30s) (31800 38%) 0.2807\n",
      "12m 46s (- 20m 26s) (32000 38%) 0.2501\n",
      "12m 51s (- 20m 21s) (32200 38%) 0.2933\n",
      "12m 56s (- 20m 17s) (32400 38%) 0.2911\n",
      "13m 1s (- 20m 12s) (32600 39%) 0.2715\n",
      "13m 5s (- 20m 7s) (32800 39%) 0.3059\n",
      "13m 10s (- 20m 2s) (33000 39%) 0.2501\n",
      "13m 15s (- 19m 58s) (33200 39%) 0.2841\n",
      "13m 20s (- 19m 53s) (33400 40%) 0.2399\n",
      "13m 25s (- 19m 48s) (33600 40%) 0.2745\n",
      "13m 29s (- 19m 43s) (33800 40%) 0.3099\n",
      "13m 34s (- 19m 38s) (34000 40%) 0.2511\n",
      "13m 39s (- 19m 33s) (34200 41%) 0.2906\n",
      "13m 44s (- 19m 28s) (34400 41%) 0.2627\n",
      "13m 48s (- 19m 24s) (34600 41%) 0.2807\n",
      "13m 53s (- 19m 19s) (34800 41%) 0.2920\n",
      "13m 58s (- 19m 14s) (35000 42%) 0.2904\n",
      "14m 3s (- 19m 9s) (35200 42%) 0.2579\n",
      "14m 8s (- 19m 4s) (35400 42%) 0.2220\n",
      "14m 12s (- 19m 0s) (35600 42%) 0.2997\n",
      "14m 17s (- 18m 55s) (35800 43%) 0.2336\n",
      "14m 22s (- 18m 50s) (36000 43%) 0.2572\n",
      "14m 27s (- 18m 45s) (36200 43%) 0.2885\n",
      "14m 31s (- 18m 40s) (36400 43%) 0.2794\n",
      "14m 36s (- 18m 36s) (36600 43%) 0.2829\n",
      "14m 41s (- 18m 31s) (36800 44%) 0.2942\n",
      "14m 46s (- 18m 26s) (37000 44%) 0.2870\n",
      "14m 51s (- 18m 21s) (37200 44%) 0.2403\n",
      "14m 56s (- 18m 17s) (37400 44%) 0.3352\n",
      "15m 1s (- 18m 12s) (37600 45%) 0.2511\n",
      "15m 5s (- 18m 7s) (37800 45%) 0.2964\n",
      "15m 10s (- 18m 3s) (38000 45%) 0.2479\n",
      "15m 15s (- 17m 58s) (38200 45%) 0.3242\n",
      "15m 20s (- 17m 53s) (38400 46%) 0.3179\n",
      "15m 25s (- 17m 48s) (38600 46%) 0.2559\n",
      "15m 29s (- 17m 43s) (38800 46%) 0.2529\n",
      "15m 34s (- 17m 39s) (39000 46%) 0.2650\n",
      "15m 39s (- 17m 34s) (39200 47%) 0.2710\n",
      "15m 44s (- 17m 29s) (39400 47%) 0.2379\n",
      "15m 48s (- 17m 24s) (39600 47%) 0.2879\n",
      "15m 53s (- 17m 19s) (39800 47%) 0.2415\n",
      "15m 58s (- 17m 14s) (40000 48%) 0.2427\n",
      "16m 3s (- 17m 10s) (40200 48%) 0.2636\n",
      "16m 8s (- 17m 5s) (40400 48%) 0.2855\n",
      "16m 12s (- 17m 0s) (40600 48%) 0.2642\n",
      "16m 17s (- 16m 55s) (40800 49%) 0.2796\n",
      "16m 22s (- 16m 51s) (41000 49%) 0.2631\n",
      "16m 27s (- 16m 46s) (41200 49%) 0.2360\n",
      "16m 31s (- 16m 41s) (41400 49%) 0.2866\n",
      "16m 36s (- 16m 36s) (41600 50%) 0.3142\n",
      "16m 41s (- 16m 31s) (41800 50%) 0.2619\n",
      "16m 46s (- 16m 26s) (42000 50%) 0.2811\n",
      "16m 51s (- 16m 22s) (42200 50%) 0.2789\n",
      "16m 55s (- 16m 17s) (42400 50%) 0.2276\n",
      "17m 0s (- 16m 12s) (42600 51%) 0.2731\n",
      "17m 5s (- 16m 7s) (42800 51%) 0.2636\n",
      "17m 9s (- 16m 2s) (43000 51%) 0.3246\n",
      "17m 14s (- 15m 58s) (43200 51%) 0.2818\n",
      "17m 19s (- 15m 53s) (43400 52%) 0.2687\n",
      "17m 24s (- 15m 48s) (43600 52%) 0.2485\n",
      "17m 29s (- 15m 43s) (43800 52%) 0.2229\n",
      "17m 33s (- 15m 38s) (44000 52%) 0.2218\n",
      "17m 38s (- 15m 33s) (44200 53%) 0.2425\n",
      "17m 43s (- 15m 28s) (44400 53%) 0.3249\n",
      "17m 48s (- 15m 24s) (44600 53%) 0.2472\n",
      "17m 52s (- 15m 19s) (44800 53%) 0.2245\n",
      "17m 57s (- 15m 14s) (45000 54%) 0.2214\n",
      "18m 2s (- 15m 9s) (45200 54%) 0.2520\n",
      "18m 7s (- 15m 5s) (45400 54%) 0.2592\n",
      "18m 11s (- 15m 0s) (45600 54%) 0.2258\n",
      "18m 16s (- 14m 55s) (45800 55%) 0.2609\n",
      "18m 21s (- 14m 50s) (46000 55%) 0.2169\n",
      "18m 25s (- 14m 45s) (46200 55%) 0.2888\n",
      "18m 30s (- 14m 40s) (46400 55%) 0.2451\n",
      "18m 35s (- 14m 36s) (46600 56%) 0.2266\n",
      "18m 40s (- 14m 31s) (46800 56%) 0.2518\n",
      "18m 45s (- 14m 26s) (47000 56%) 0.2716\n",
      "18m 50s (- 14m 21s) (47200 56%) 0.2804\n",
      "18m 55s (- 14m 17s) (47400 56%) 0.2328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19m 1s (- 14m 13s) (47600 57%) 0.2426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3df443ab7090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     83194\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m83194\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_back_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/zedroman/Documents/Sonia_Data/test_models4/encoder_epoch{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/zedroman/Documents/Sonia_Data/test_models4/encoder_back_epoch{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-348ebe0fb408>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, encoder_back, decoder, n_iters, encoder_optimizer, encoder_back_optimizer, decoder_optimizer, print_every, plot_every, learning_rate, epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         loss = train(input_tensor, input_tensor_back, target_tensor, encoder, encoder_back,\n\u001b[0;32m---> 19\u001b[0;31m                      decoder, encoder_optimizer,encoder_back_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-398a140e3e27>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, input_tensor_back, target_tensor, encoder, encoder_back, decoder, encoder_optimizer, encoder_back_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(6, 100):\n",
    "#     83194\n",
    "    trainIters(encoder, encoder_back, attn_decoder, 83194, encoder_optimizer, encoder_back_optimizer, decoder_optimizer, print_every=200, epoch=epoch, learning_rate=learning_rate)\n",
    "    torch.save(encoder, '/home/zedroman/Documents/Sonia_Data/test_models4/encoder_epoch{}'.format(epoch))\n",
    "    torch.save(encoder_back, '/home/zedroman/Documents/Sonia_Data/test_models4/encoder_back_epoch{}'.format(epoch))\n",
    "    torch.save(attn_decoder, '/home/zedroman/Documents/Sonia_Data/test_models4/decoder_epoch{}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epo = 1\n",
    "encoder = torch.load('/home/zedroman/Documents/Sonia_Data/test_models4/encoder_epoch{}'.format(epo))\n",
    "attn_decoder = torch.load( '/home/zedroman/Documents/Sonia_Data/test_models4/decoder_epoch{}'.format(epo))\n",
    "encoder.eval()\n",
    "attn_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> MONNIN\n",
      "= M_AA_N_IH_N\n",
      "< M_AA_N_IH_N\n",
      "\n",
      "> SOWED\n",
      "= S_AW_D\n",
      "< S_OW_D\n",
      "\n",
      "> AFTERNOONS\n",
      "= AE_F_T_ER_N_UW_N_Z\n",
      "< AE_F_T_ER_N_UW_N_Z\n",
      "\n",
      "> MOBILIZING\n",
      "= M_OW_B_AH_L_AY_Z_IH_NG\n",
      "< M_OW_B_AH_L_AY_Z_IH_NG\n",
      "\n",
      "> LUETH\n",
      "= L_UW_TH\n",
      "< L_UW_TH\n",
      "\n",
      "> GEIER\n",
      "= G_AY_ER\n",
      "< G_AY_ER\n",
      "\n",
      "> SKIDMORE\n",
      "= S_K_IH_D_M_AO_R\n",
      "< S_K_IH_D_M_AO_R\n",
      "\n",
      "> HUNTON\n",
      "= HH_AH_N_T_AH_N\n",
      "< HH_AH_N_T_AH_N\n",
      "\n",
      "> PROVOCATIVE\n",
      "= P_R_OW_V_AA_K_AH_T_IH_V\n",
      "< P_R_AH_V_AA_K_AH_T_IH_V\n",
      "\n",
      "> RABAGO\n",
      "= R_AA_B_AA_G_OW\n",
      "< R_AA_B_AA_G_OW\n",
      "\n",
      "0.5546\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, encoder_back, attn_decoder)\n",
    "checkAccuracy(encoder,encoder_back, attn_decoder)\n",
    "# evaluateRandomly(encoder1, attn_decoder1)\n",
    "# checkAccuracy(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zedroman/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "txt = pd.read_csv('/home/zedroman/Documents/Sonia_Data/eng_phonetics/test(1).csv').as_matrix()\n",
    "index = txt[:, 0]\n",
    "test = txt[:,1]\n",
    "ans = []\n",
    "for word in test:\n",
    "    output_words, attentions = evaluate(encoder, encoder_back, attn_decoder, word)\n",
    "    ans.append('_'.join(output_words))\n",
    "ans=np.array(ans)\n",
    "ret = pd.DataFrame({'Id':index, 'Transcription':ans})\n",
    "ret.to_csv(\"/home/zedroman/Documents/Sonia_Data/eng_phonetics/ans.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
