{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from mido import Message, MetaMessage\n",
    "import mido\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "pwd = \"/home/zedroman/Documents/Sonia_Data/Songs/60 FREE Melodies (MIDI)/\"\n",
    "savepwd=\"/home/zedroman/Documents/Sonia_Data/melodies\"\n",
    "music = sorted([f for f in os.listdir(pwd) if f[len(f)-4:len(f)] == \".mid\"])\n",
    "sos = 0\n",
    "eos = 1\n",
    "message_type = {\"note_on\":1, \"note_off\":0}\n",
    "type_message = {1:\"note_on\", 0:\"note_off\"}\n",
    "tempo = 500000 * 5\n",
    "hidden_size = 586\n",
    "classes = 586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "device=\"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random(music):\n",
    "    randoms = []\n",
    "    for i in range(len(music)):\n",
    "        r = []\n",
    "        for j in range(3):\n",
    "            r.append([random.random() * 10 for i in range(hidden_size)])\n",
    "        randoms.append(r)\n",
    "    return randoms\n",
    "random_starts = create_random(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0(sos) 1(eos) 2 - 129(note_on) 130 - 257(note_off) 258 - 385(velocity) 386-585 //386-395,396-405, 406-415, 416-425 (time_shift)\n",
    "\n",
    "def encode_type(tp, num):\n",
    "    if (tp == \"sos\"):\n",
    "        return 0\n",
    "    if (tp == \"eos\"):\n",
    "        return eos\n",
    "    if (tp == \"note_on\"):\n",
    "        return num + 2\n",
    "    if (tp == \"note_off\"):\n",
    "        return num + 130\n",
    "    if (tp == \"velocity\"):\n",
    "        return num + 258\n",
    "    if (tp == \"time\"):\n",
    "        t = (num // 8) + 386\n",
    "        if (t < 586):\n",
    "            return t\n",
    "        return 585\n",
    "    return -1\n",
    "\n",
    "def get_type(c):\n",
    "    if(c == 0):\n",
    "        return \"sos\", c\n",
    "    if(c == 1):\n",
    "        return \"eos\", c\n",
    "    if(c > 1 and c <= 129):\n",
    "        return \"note_on\", c - 2\n",
    "    \n",
    "    if(c >= 130 and c < 258):\n",
    "        return \"note_off\", c - 130\n",
    "    \n",
    "    if(c>=258 and c < 386):\n",
    "        return \"velocity\", c - 258\n",
    "    \n",
    "    if(c>=386 and c < 586):\n",
    "        return \"time\", int((c - 386) * 8)\n",
    "    \n",
    "    print(c)\n",
    "    return \"wtf\", -1\n",
    "    \n",
    "\n",
    "\n",
    "def midi_to_list(mid=None, pwd=None, tensor=True):\n",
    "    if(mid==None):\n",
    "          mid = mido.MidiFile(pwd)\n",
    "    sample=[]\n",
    "    velocity = -1\n",
    "    for i, track in enumerate(mid.tracks):\n",
    "        j = 0\n",
    "        for msg in track:\n",
    "            j += 1\n",
    "            if (j > 1000):\n",
    "                break\n",
    "            if (msg.type == \"note_off\" or msg.type == \"note_on\"):\n",
    "                if (msg.time != 0):\n",
    "                    c= encode_type(\"time\", msg.time)\n",
    "                    if (c != -1):\n",
    "                        sample.append(c)\n",
    "#                         for i in c:\n",
    "#                             sample.append(i)\n",
    "                if (msg.velocity != velocity):\n",
    "                    c = encode_type(\"velocity\", msg.velocity)\n",
    "                    if (c != -1): \n",
    "                        sample.append(c)\n",
    "                    velocity = msg.velocity\n",
    "                if (msg.type == \"note_on\"):\n",
    "                    c = encode_type(\"note_on\", msg.note)\n",
    "                    if (c != -1): \n",
    "                        sample.append(c)\n",
    "                if (msg.type == \"note_off\"):\n",
    "                    c = encode_type(\"note_off\", msg.note)\n",
    "                    if (c != -1): \n",
    "                        sample.append(c)\n",
    "    sample.append(eos)\n",
    "    if (tensor):\n",
    "        return torch.tensor(sample, device=device)\n",
    "    else:\n",
    "        return sample\n",
    "#     return sorted(sample, key=lambda x: x[-1])\n",
    "\n",
    "def check_midi(sample):\n",
    "    note_on = {}\n",
    "    dele = []\n",
    "    for j,i in enumerate(sample):\n",
    "#         print(i)\n",
    "        tp, nt = get_type(i)\n",
    "        if (tp == \"note_on\"):\n",
    "            if(nt in note_on):\n",
    "                dele.append(j);\n",
    "            note_on[nt] = 1;\n",
    "        if (tp == \"note_off\"):\n",
    "            if(nt in note_on):\n",
    "                del note_on[nt]\n",
    "            else:\n",
    "                dele.append(j)\n",
    "    for i in range(len(dele) - 1, -1, -1):\n",
    "        del(sample[dele[i]])\n",
    "    for i in note_on:\n",
    "        sample.append(encode_type(\"note_off\", i))\n",
    "\n",
    "def list_to_midi(sample):\n",
    "    print(\"was: \",len(sample))\n",
    "    check_midi(sample)\n",
    "    print(\"now: \",len(sample))\n",
    "    \n",
    "    midi = mido.MidiFile(type=0)\n",
    "    tr = mido.MidiTrack()\n",
    "    midi.tracks.append(tr)\n",
    "    tr.append(MetaMessage(\"set_tempo\", tempo=tempo, time=0))\n",
    "    velocity = 0\n",
    "    time = 0\n",
    "    for i in sample:\n",
    "        tp, nt = get_type(i)\n",
    "        if (tp == \"velocity\"):\n",
    "            velocity = nt\n",
    "        if (tp == \"time\"):\n",
    "            time += nt\n",
    "        if (tp == \"note_off\" or tp == \"note_on\"):\n",
    "#             print(nt, velocity, time)\n",
    "            tr.append(Message(tp, note=nt, velocity=velocity, time=time, channel=0))\n",
    "            time = 0\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in (music):\n",
    "#     midi_file = mido.MidiFile(pwd + file)\n",
    "#     sample = midi_to_list(mid=midi_file, tensor=False)\n",
    "#     print(sample)\n",
    "#     midi = list_to_midi(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru1 = nn.GRU(classes, hidden_size)\n",
    "        self.gru2 = nn.GRU(classes, hidden_size)\n",
    "        self.gru3 = nn.GRU(classes, hidden_size)\n",
    "        self.out = nn.Linear(classes, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "#         output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(input)\n",
    "#         print(output.shape, hidden[0].shape)\n",
    "        output, hidden[0] = self.gru1(output, hidden[0])\n",
    "        output = F.relu(output)\n",
    "        output, hidden[1] = self.gru2(output, hidden[1])\n",
    "        output = F.relu(output)\n",
    "        output, hidden[2] = self.gru3(output, hidden[2])\n",
    "        \n",
    "        \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "def one_hot(c):\n",
    "    x = torch.zeros(classes, device=device, dtype=torch.float)\n",
    "    x[c] = 1;\n",
    "    return x.view(1,1,-1)\n",
    "\n",
    "def train(target_tensor, decoder, decoder_optimizer, criterion, max_length=max_len, num = -1):\n",
    "    decoder_optimizer.zero_grad()\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "#     decoder_input = torch.tensor([[sos]], device=device)\n",
    "    decoder_input = one_hot(sos)\n",
    "    decoder_hidden =   [torch.tensor(random_starts[num][0], device=device, dtype=torch.float).view(1,1,-1),\n",
    "                        torch.tensor(random_starts[num][1], device=device, dtype=torch.float).view(1,1,-1),\n",
    "                        torch.tensor(random_starts[num][2], device=device, dtype=torch.float).view(1,1,-1)]\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "#             if di == max_len:\n",
    "#                 break\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di:di+1])\n",
    "            decoder_input = one_hot(target_tensor[di])  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di:di+1])\n",
    "            if decoder_input.item() == eos:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(decoder, n_iters,decoder_optimizer, print_every=len(music), epoch=0):\n",
    "    last_loss = 100;\n",
    "    learning_rate = 0.001\n",
    "    start = time.time()\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = music[iter % (len(music))]\n",
    "#         print(training_pair)\n",
    "        midi_file = mido.MidiFile(pwd + training_pair)\n",
    "        target_tensor = midi_to_list(mid=midi_file)\n",
    "        loss = train(target_tensor,\n",
    "                     decoder, decoder_optimizer, criterion, num = iter % (len(music)))\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            if (print_loss_total / print_every > last_loss):\n",
    "#                 learning_rate /= 10\n",
    "                print(\"learning rate change :\", learning_rate)\n",
    "#                 decoder_optimizer = optim.Adam(decoder.parameters() , lr=learning_rate)\n",
    "            last_loss = print_loss_total / print_every\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "# decoder = DecoderRNN(hidden_size, 586).to(device)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters() , lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 41s (- 114m 40s) (60 0%) 1.4454\n",
      "1m 23s (- 114m 1s) (120 1%) 1.4385\n",
      "2m 4s (- 113m 21s) (180 1%) 1.4338\n",
      "2m 46s (- 112m 39s) (240 2%) 1.4268\n",
      "3m 27s (- 111m 57s) (300 3%) 1.4200\n",
      "4m 9s (- 111m 15s) (360 3%) 1.4130\n",
      "4m 50s (- 110m 34s) (420 4%) 1.4066\n",
      "5m 32s (- 109m 54s) (480 4%) 1.4001\n",
      "6m 14s (- 109m 13s) (540 5%) 1.3932\n",
      "6m 55s (- 108m 32s) (600 6%) 1.3873\n",
      "7m 37s (- 107m 52s) (660 6%) 1.3807\n",
      "8m 18s (- 107m 10s) (720 7%) 1.3746\n",
      "9m 0s (- 106m 27s) (780 7%) 1.3682\n",
      "9m 41s (- 105m 46s) (840 8%) 1.3618\n",
      "10m 24s (- 105m 18s) (900 9%) 1.3562\n",
      "11m 8s (- 104m 52s) (960 9%) 1.3505\n",
      "11m 51s (- 104m 27s) (1020 10%) 1.3452\n",
      "12m 34s (- 103m 53s) (1080 10%) 1.3397\n",
      "13m 18s (- 103m 24s) (1140 11%) 1.3346\n",
      "14m 1s (- 102m 51s) (1200 12%) 1.3288\n",
      "14m 44s (- 102m 14s) (1260 12%) 1.3225\n",
      "15m 27s (- 101m 35s) (1320 13%) 1.3164\n",
      "16m 10s (- 101m 2s) (1380 13%) 1.3106\n",
      "16m 53s (- 100m 25s) (1440 14%) 1.3051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e132a7fb6823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-ec5cfc96cbc4>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(decoder, n_iters, decoder_optimizer, print_every, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidi_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmidi_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         loss = train(target_tensor,\n\u001b[0;32m---> 15\u001b[0;31m                      decoder, decoder_optimizer, criterion, num = iter % (len(music)))\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-283a9377a4a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target_tensor, decoder, decoder_optimizer, criterion, max_length, num)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainIters(decoder, 10000, decoder_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(decoder,num=-1, max_length=max_len):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        decoder_input = torch.tensor([[sos]], device=device)  # SOS\n",
    "        decoder_hidden = []\n",
    "        for j in range(3):\n",
    "            decoder_hidden.append([random.random() * 10 for i in range(hidden_size)])\n",
    "        decoder_hidden =   [torch.tensor(decoder_hidden[0], device=device).view(1,1,-1),\n",
    "                        torch.tensor(decoder_hidden[1], device=device).view(1,1,-1),\n",
    "                        torch.tensor(decoder_hidden[2], device=device).view(1,1,-1)]\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(2)\n",
    "            topv = topv.max().item() - topv.cpu()[0].numpy()\n",
    "            summ = topv.sum()\n",
    "            chosen = np.random.choice(topi[0].cpu(), p= topv / summ)\n",
    "            decoder_input = torch.tensor(chosen, device=device)\n",
    "            if decoder_input == eos:\n",
    "#                 decoded_words.append('<EOS>')\n",
    "#                 break\n",
    "                decoder_input = torch.tensor([[sos]], device=device)\n",
    "            else:\n",
    "                decoded_words.append(chosen)\n",
    "\n",
    "#             decoder_input = topi.data.topk(1)[1].squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(number, decoder):\n",
    "    for i in range(number):\n",
    "        new_music = evaluate(decoder)\n",
    "        midi = list_to_midi(new_music)\n",
    "        print(midi.length)\n",
    "        midi.save(savepwd +\"test\" + str(i) + \".mid\")\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last = generate(10, decoder)\n",
    "for track in last.tracks:\n",
    "    for msg in track:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in new_music:\n",
    "    print(get_type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    midi = mido.MidiFile(\"/home/zedroman/Documents/Sonia_Data/Songs/test_from.mid\")\n",
    "#     midi = mido.MidiFile()\n",
    "#     tr = mido.MidiTrack()\n",
    "#     midi.tracks.append(tr)\n",
    "#     tr.append(Message(\"note_on\", velocity = 10, time= 1111, channel=0))\n",
    "    sample = midi_to_list(midi, tensor=False)\n",
    "#     for i in sample:\n",
    "#         print(i)\n",
    "    midi = list_to_midi(sample)\n",
    "    midi.save(\"/home/zedroman/Documents/Sonia_Data/Songs/test_to.mid\")\n",
    "tempo = 500000 * 5\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = mido.MidiFile(pwd + \"2.mid\")\n",
    "for i, track in enumerate(midi.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    for msg in track:\n",
    "        print(msg)\n",
    "# tmp = music[0]\n",
    "# music[0] =music[2]\n",
    "# music[2] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(), '/home/zedroman/Documents/Sonia_Data/test_models4/decoder5')\n",
    "import pickle\n",
    "with open('/home/zedroman/Documents/Sonia_Data/test_models4/starts4', \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(random_starts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2 = DecoderRNN(hidden_size, 586).to(device)\n",
    "checkpoint = torch.load('/home/zedroman/Documents/Sonia_Data/test_models4/decoder5')\n",
    "decoder2.load_state_dict(checkpoint)\n",
    "# decoder = torch.load('/home/zedroman/Documents/Sonia_Data/test_models4/decoder4')\n",
    "with open('/home/zedroman/Documents/Sonia_Data/test_models4/starts4', \"rb\") as fp:   # Unpickling\n",
    "    random_starts2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
