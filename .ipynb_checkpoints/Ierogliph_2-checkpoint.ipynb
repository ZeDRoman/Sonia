{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = 3\n",
    "n_c = 4\n",
    "train_path = \"/home/zedroman/Documents/Sonia/Ierogliph/mixed/train_{}.npy\"\n",
    "ans_path = \"/home/zedroman/Documents/Sonia/Ierogliph/mixed/ans_{}.npy\"\n",
    "\n",
    "check_path = \"/home/zedroman/Documents/Sonia/Ierogliph/mixed/check_{}.npy\"\n",
    "check_ans_path=\"/home/zedroman/Documents/Sonia/Ierogliph/mixed/check_ans_{}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "i_width = 56\n",
    "i_height = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splited(num):\n",
    "    data = np.load(train_path.format(num))\n",
    "    data = torch.from_numpy(data.reshape((data.shape[0],1, 56, 56))).float() / 255\n",
    "    data = torch.split(data, 50)\n",
    "    ans = torch.from_numpy(np.load(ans_path.format(num))).long()\n",
    "    ans = torch.split(ans, 50)\n",
    "    return data, ans\n",
    "\n",
    "def get_check(num):\n",
    "    data = np.load(check_path.format(num))\n",
    "    data = torch.from_numpy(data.reshape((data.shape[0],1, 56, 56))).float() / 255\n",
    "    ans = torch.from_numpy(np.load(check_ans_path.format(num))).long()\n",
    "    return data, ans\n",
    "\n",
    "def get_data_check(num):\n",
    "    data = np.load(train_path.format(num))\n",
    "    data = torch.from_numpy(data.reshape((data.shape[0],1, 56, 56))).float() / 255\n",
    "    ans = torch.from_numpy(np.load(ans_path.format(num))).long()\n",
    "    return data, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, ans = get_data_splited(0)\n",
    "im = data[0][3].numpy()\n",
    "im = np.reshape(im, (i_height, i_width))\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc0 = nn.Linear(i_height * i_width, 1300) # params - 2D-Tensor 28*28x100\n",
    "        self.fc2 = nn.Linear(1300, 1000) # params - 2D-Tensor 28*28x100\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, i_height * i_width)\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1000, momentum=0.9)\n",
    "\n",
    "def train(epoch):\n",
    "    for j in range(n_t):\n",
    "        print(j, \"out of\", n_t)\n",
    "        x_batches, y_batches = get_data_splited(j)\n",
    "        bar = progressbar.ProgressBar(maxval=len(x_batches)).start()\n",
    "        for i in range(len(x_batches)):\n",
    "            bar.update(i)\n",
    "            data, target = Variable(x_batches[i]), Variable(y_batches[i])\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        bar.finish()\n",
    "        print(loss)\n",
    "\n",
    "def check(model, x_test, y_test):\n",
    "    train_correct = 0\n",
    "    test_ans = model(x_test)\n",
    "    pred = test_ans.data.max(1, keepdim=True)[1]\n",
    "    train_correct += pred.eq(y_test.data.view_as(pred)).sum()\n",
    "    return((float(train_correct) / x_test.shape[0]) * 100)\n",
    "\n",
    "def create(model, epochs):\n",
    "    train_set_acc = []\n",
    "    test_set_acc = []\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        print(epoch)\n",
    "        train(epoch)\n",
    "        data, ans = get_data_check(0)\n",
    "        acc = check(model, data, ans)\n",
    "        train_set_acc.append(acc)\n",
    "        print(\"train\", acc)\n",
    "        data, ans = get_check(0)\n",
    "        acc = check(model, data, ans)\n",
    "        test_set_acc.append(acc)\n",
    "        print(\"check\", acc)\n",
    "\n",
    "    plt.plot(np.arange(0, epochs), train_set_acc, color='cyan')\n",
    "    plt.show()\n",
    "    plt.plot(np.arange(0, epochs), test_set_acc, color='cyan')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final accuracy\")\n",
    "print(\"Train:\")\n",
    "print(check(model, x, y))\n",
    "print(\"Test:\")\n",
    "print(check(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "output = Variable(torch.randn(10, 120).float())\n",
    "target = Variable(torch.FloatTensor(10).uniform_(0, 120).long())\n",
    "\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = (np.load(\"/home/zedroman/Documents/Sonia/Ierogliph/train.npy\"))\n",
    "\n",
    "tensor_data = torch.empty((data.shape[0],1,data[0, 0].shape[0], data[0, 0].shape[1]))\n",
    "tensor_ans = torch.empty((data.shape[0])).long()\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    tensor_data[i,0,:,:] = torch.from_numpy(data[i, 0])\n",
    "    tensor_ans[i] = data[i,1]\n",
    "del data\n",
    "\n",
    "trainset = torch.utils.data.TensorDataset(tensor_data, tensor_ans)\n",
    "del tensor_ans\n",
    "del tensor_data\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "del trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "     \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 11 * 11, 120)\n",
    "        self.fc2 = nn.Linear(120, 600)\n",
    "        self.fc3 = nn.Linear(600, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 11 * 11)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"/home/zedroman/Documents/Sonia/Ierogliph/models/first.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (np.load(\"/home/zedroman/Documents/Sonia/Ierogliph/testing.npy\"))\n",
    "\n",
    "tensor_data = torch.empty((data.shape[0],1,data[0, 0].shape[0], data[0, 0].shape[1]))\n",
    "tensor_ans = torch.empty((data.shape[0])).long()\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    tensor_data[i,0,:,:] = torch.from_numpy(data[i, 0])\n",
    "    tensor_ans[i] = data[i,1]\n",
    "del data\n",
    "\n",
    "testset = torch.utils.data.TensorDataset(tensor_data, tensor_ans)\n",
    "del tensor_ans\n",
    "del tensor_data\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "del testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/zedroman/Documents/Sonia/Ierogliph/models/first.txt\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    for j in range(len(data)):\n",
    "        if (predicted[j] == labels[j]):\n",
    "            correct+=1\n",
    "        total += 1\n",
    "    if (i % 100 == 99):\n",
    "        print(correct/total * 100)\n",
    "            \n",
    "print('Finished Training')\n",
    "print(correct/total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "data = \"/home/zedroman/Documents/Sonia/Ierogliph/test.npy/test.npy\"\n",
    "test_csv = np.load(data)\n",
    "test = np.empty((test_csv.shape[0], 1,  i_height, i_width))\n",
    "for i in range(test.shape[0]): \n",
    "    test[i,0, :, :] = scipy.misc.imresize(test_csv[i], (i_height, i_width))\n",
    "test_csv = None\n",
    "test = 255 - test\n",
    "test = torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_height = 56\n",
    "i_width = 56\n",
    "import json\n",
    "with open('/home/zedroman/Documents/Sonia/Ierogliph/itoc.txt', 'r') as outfile:  \n",
    "    itoc = json.load(outfile)\n",
    "with open('/home/zedroman/Documents/Sonia/Ierogliph/ctoi.txt', 'r') as outfile:  \n",
    "    ctoi = json.load(outfile)\n",
    "    \n",
    "def itocf(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = itoc[str(x[i])]\n",
    "        \n",
    "def ctoif(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = ctoi[x[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(model, x_test):\n",
    "    test_ans = model(x_test)\n",
    "    pred = test_ans.data.max(1, keepdim=True)[1]\n",
    "    itocf(pred)\n",
    "    nums = torch.arange(x_test.shape[0]).reshape((x_test.shape[0], 1)) + 1\n",
    "    return(torch.cat((nums, pred), 1))\n",
    "\n",
    "print(test.shape)\n",
    "ans = get_ans(model, test)\n",
    "print(ans)\n",
    "import pandas as pd\n",
    "# df = pd.DataFrame(ans.numpy)\n",
    "# df.to_csv(\"/home/zedroman/Documents/Sonia/mnist/test.csv\")\n",
    "ans = ans.numpy()\n",
    "np.savetxt(\"/home/zedroman/Documents/Sonia/Ierogliph/ans.csv\", ans, fmt=\"%d\", delimiter=\",\")\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
